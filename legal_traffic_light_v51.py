"""
Legal Traffic Light v5.1 - Enterprise Edition
–°–∏—Å—Ç–µ–º–∞ –∞–Ω–∞–ª–∏–∑–∞ –¥–æ–≥–æ–≤–æ—Ä–æ–≤ –Ω–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –†–µ–≥–ª–∞–º–µ–Ω—Ç—É –ê–û ¬´–ù–ü–ö¬ª

–§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª:
- –ó–∞–≥—Ä—É–∑–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: TXT, DOCX, PDF
- –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–æ–≤: PDF, DOCX, JSON
- –ê–ª–≥–æ—Ä–∏—Ç–º —Å—Ä–∞–≤–Ω–µ–Ω–∏—è: Jaccard + TF-IDF + N-grams + Levenshtein
- AI-–∞–Ω–∞–ª–∏–∑ —Ä–∏—Å–∫–æ–≤ (OpenAI/Anthropic)
- –ò—Å—Ç–æ—Ä–∏—è –∞–Ω–∞–ª–∏–∑–æ–≤, —Å—Ç–∞—Ç—É—Å —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–∏—è –Æ–î

–ó–∞–ø—É—Å–∫: streamlit run app.py
–ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏: pip install streamlit python-docx fpdf2 PyPDF2 requests
"""

import streamlit as st
import re
import json
import html
import math
import hashlib
import base64
import io
import os
from datetime import datetime, date
from typing import Dict, List, Tuple, Optional, Any, Set
from dataclasses import dataclass, field, asdict
from enum import Enum
from collections import Counter
import difflib

# ============================================================================
# –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø
# ============================================================================

st.set_page_config(
    page_title="Legal Traffic Light v5.1 | –ê–û –ù–ü–ö",
    page_icon="üö¶",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ============================================================================
# –ö–û–ù–°–¢–ê–ù–¢–´ –ò–ó –†–ï–ì–õ–ê–ú–ï–ù–¢–ê
# ============================================================================

class RiskZone(Enum):
    GREEN = "green"
    YELLOW = "yellow"
    RED = "red"

class DocumentForm(Enum):
    TYPICAL = "typical"
    COUNTERPARTY = "counterparty"
    FREE = "free"
    MODIFIED_TF = "modified_tf"
    SELF_DEVELOPED = "self"

class LegalStatus(Enum):
    NOT_SUBMITTED = "not_submitted"
    NO_INFO = "no_info"
    SUBMITTED = "submitted"
    APPROVED = "approved"
    REJECTED = "rejected"
    IN_PROGRESS = "in_progress"

LEGAL_STATUS_LABELS = {
    LegalStatus.NOT_SUBMITTED: "üî¥ –ù–µ –ø–æ—Å—Ç—É–ø–∞–ª –Ω–∞ —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–∏–µ –Æ–î",
    LegalStatus.NO_INFO: "üü° –ù–µ—Ç —Å–≤–µ–¥–µ–Ω–∏–π –æ –ø–æ—Å—Ç—É–ø–ª–µ–Ω–∏–∏ –≤ –¥–∞–Ω–Ω–æ–π —Ä–µ–¥–∞–∫—Ü–∏–∏",
    LegalStatus.SUBMITTED: "üü° –ü–æ—Å—Ç—É–ø–∞–ª –Ω–∞ —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–∏–µ",
    LegalStatus.APPROVED: "üü¢ –°–æ–≥–ª–∞—Å–æ–≤–∞–Ω –Æ–î",
    LegalStatus.REJECTED: "üî¥ –û—Ç–∫–ª–æ–Ω–µ–Ω –Æ–î",
    LegalStatus.IN_PROGRESS: "üü° –ù–∞ —Ä–∞—Å—Å–º–æ—Ç—Ä–µ–Ω–∏–∏ –Æ–î",
}

class Thresholds:
    GREEN_TF_MAX = 100_000
    GREEN_NON_TF_MAX = 50_000
    YELLOW_MAX = 5_000_000
    RED_MIN = 5_000_001
    TENDER_RED = 3_000_000
    SINGLE_SUPPLIER_YELLOW = 100_000
    CONTRACT_CONTROL_YEARS = 3

class Deadlines:
    STANDARD = 5
    EXTENDED = 10
    URGENT = 1

# –ü–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è –ê–û –ù–ü–ö
DEPARTMENTS = [
    "–î–µ–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ –ø–µ—Ä–µ–≤–æ–∑–æ–∫ (—É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –ø–æ–¥–≤–∏–∂–Ω–æ–π —Å–æ—Å—Ç–∞–≤)",
    "–î–µ–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç –ø–æ –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏—è–º",
    "–î–µ–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç –ø–æ —Ä–∞—Å—á–µ—Ç–∞–º —Å –û–ê–û \"–†–ñ–î\"",
    "–î–µ–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç –ø–æ —Å–≤—è–∑—è–º —Å –æ–±—â–µ—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å—é",
    "–î–µ–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç –ø–æ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—é –ø–µ—Ä—Å–æ–Ω–∞–ª–æ–º",
    "–î–µ–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç –ø–æ–¥–≤–∏–∂–Ω–æ–≥–æ —Å–æ—Å—Ç–∞–≤–∞",
    "–î–µ–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç —Ä–∞–∑–≤–∏—Ç–∏—è –ø–µ—Ä—Å–æ–Ω–∞–ª–∞",
    "–î–µ–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç —Å—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫–∏—Ö –ø—Ä–æ–µ–∫—Ç–æ–≤",
    "–î–µ–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç —Ñ–∏–Ω–∞–Ω—Å–æ–≤–æ–≥–æ –∫–æ–Ω—Ç—Ä–æ–ª–ª–∏–Ω–≥–∞",
    "–ö–∞–∑–Ω–∞—á–µ–π—Å—Ç–≤–æ",
    "–Æ—Ä–∏–¥–∏—á–µ—Å–∫–∏–π –¥–µ–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç",
    "–û—Ç–¥–µ–ª –ø–æ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—é —Ä–∏—Å–∫–∞–º–∏",
    "–°–ª—É–∂–±–∞ –æ—Ö—Ä–∞–Ω—ã —Ç—Ä—É–¥–∞",
]

POSITIONS = [
    "–°–ø–µ—Ü–∏–∞–ª–∏—Å—Ç",
    "–í–µ–¥—É—â–∏–π —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç",
    "–ì–ª–∞–≤–Ω—ã–π —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç",
    "–ù–∞—á–∞–ª—å–Ω–∏–∫ –æ—Ç–¥–µ–ª–∞",
    "–ó–∞–º–µ—Å—Ç–∏—Ç–µ–ª—å —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è",
    "–ù–∞—á–∞–ª—å–Ω–∏–∫ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è",
    "–ó–∞–º–µ—Å—Ç–∏—Ç–µ–ª—å —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—è –¥–µ–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç–∞",
    "–†—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å –¥–µ–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç–∞",
    "–ó–∞–º–µ—Å—Ç–∏—Ç–µ–ª—å –≥–µ–Ω–µ—Ä–∞–ª—å–Ω–æ–≥–æ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∞",
    "–ì–µ–Ω–µ—Ä–∞–ª—å–Ω—ã–π –¥–∏—Ä–µ–∫—Ç–æ—Ä"
]

RED_ZONE_ALWAYS = [
    "–ê—Ä–µ–Ω–¥–∞ –≤–∞–≥–æ–Ω–æ–≤", "–õ–∏–∑–∏–Ω–≥ –≤–∞–≥–æ–Ω–æ–≤", "–ü–æ–∫—É–ø–∫–∞/–ø—Ä–æ–¥–∞–∂–∞ –≤–∞–≥–æ–Ω–æ–≤",
    "–ê—Ä–µ–Ω–¥–∞ –ª–æ–∫–æ–º–æ—Ç–∏–≤–æ–≤", "–õ–∏–∑–∏–Ω–≥ –ª–æ–∫–æ–º–æ—Ç–∏–≤–æ–≤", "–ü–æ–∫—É–ø–∫–∞/–ø—Ä–æ–¥–∞–∂–∞ –ª–æ–∫–æ–º–æ—Ç–∏–≤–æ–≤",
    "–ê—Ä–µ–Ω–¥–∞ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤", "–õ–∏–∑–∏–Ω–≥ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤", "–ü–æ–∫—É–ø–∫–∞/–ø—Ä–æ–¥–∞–∂–∞ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤",
    "–ú–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω—ã–µ –ø–µ—Ä–µ–≤–æ–∑–∫–∏ (–í–≠–î)", "–†–∞—Å—á–µ—Ç—ã –≤ –≤–∞–ª—é—Ç–µ",
    "–î–æ–≥–æ–≤–æ—Ä –Ω–∞ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫—É –ü–û", "–î–æ–≥–æ–≤–æ—Ä –Ω–∞ –≤–Ω–µ–¥—Ä–µ–Ω–∏–µ –ü–û",
    "–õ–∏—Ü–µ–Ω–∑–∏–æ–Ω–Ω–æ–µ —Å–æ–≥–ª–∞—à–µ–Ω–∏–µ –Ω–∞ –ü–û", "–°–º–∞—Ä—Ç-–∫–æ–Ω—Ç—Ä–∞–∫—Ç",
    "–ê—Ä–µ–Ω–¥–∞ –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏", "–ü–æ–∫—É–ø–∫–∞ –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏",
    "–ö—Ä–µ–¥–∏—Ç–Ω—ã–π –¥–æ–≥–æ–≤–æ—Ä", "–î–æ–≥–æ–≤–æ—Ä –∑–∞–π–º–∞", "–î–æ–≥–æ–≤–æ—Ä –∑–∞–ª–æ–≥–∞", "–î–æ–≥–æ–≤–æ—Ä –ø–æ—Ä—É—á–∏—Ç–µ–ª—å—Å—Ç–≤–∞",
    "–î–æ–≥–æ–≤–æ—Ä —Å –û–ê–û –†–ñ–î", "–°–µ—Ä–≤–∏—Å–Ω—ã–π (–≥–ª–æ–±–∞–ª—å–Ω—ã–π) –¥–æ–≥–æ–≤–æ—Ä",
    "–î–æ–≥–æ–≤–æ—Ä, —Ç—Ä–µ–±—É—é—â–∏–π –æ–¥–æ–±—Ä–µ–Ω–∏—è –°–æ–≤–µ—Ç–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä–æ–≤",
    "–¢—Ä—É–¥–æ–≤–æ–π –¥–æ–≥–æ–≤–æ—Ä —Å –¢–û–ü-–º–µ–Ω–µ–¥–∂–º–µ–Ω—Ç–æ–º",
    "–õ–æ–∫–∞–ª—å–Ω—ã–π –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–π –∞–∫—Ç (–õ–ù–ê)", "–ü–æ–ª–æ–∂–µ–Ω–∏–µ/–ü—Ä–∞–≤–∏–ª–∞/–ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è",
    "–ü—Ä–∏–∫–∞–∑ –æ –∫–æ–º–º–µ—Ä—á–µ—Å–∫–æ–π —Ç–∞–π–Ω–µ", "–ü—Ä–∏–∫–∞–∑ –æ –¥–∏—Å—Ü–∏–ø–ª–∏–Ω–∞—Ä–Ω–æ–º –≤–∑—ã—Å–∫–∞–Ω–∏–∏",
    "–ü—Ä–∏–∫–∞–∑ –æ –º–∞—Ç–µ—Ä–∏–∞–ª—å–Ω–æ–π –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏",
]

YELLOW_ZONE_TYPES = [
    "–î–æ–≥–æ–≤–æ—Ä –Ω–∞ —Ä–µ–≥—É–ª—è—Ä–Ω—ã–µ (—Ä–∞–º–æ—á–Ω—ã–µ) –ø–µ—Ä–µ–≤–æ–∑–∫–∏",
    "–î–æ–≥–æ–≤–æ—Ä –Ω–∞ –≥–æ–¥–æ–≤—ã–µ –ø–µ—Ä–µ–≤–æ–∑–∫–∏",
    "–î–æ–≥–æ–≤–æ—Ä –¢–≠–£ (—Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–Ω–æ-—ç–∫—Å–ø–µ–¥–∏—Ü–∏–æ–Ω–Ω—ã–µ —É—Å–ª—É–≥–∏)",
    "–ü–µ—Ä–µ–≤–æ–∑–∫–∞ –æ–ø–∞—Å–Ω–æ–≥–æ –≥—Ä—É–∑–∞", "–ü–µ—Ä–µ–≤–æ–∑–∫–∞ –Ω–µ–≥–∞–±–∞—Ä–∏—Ç–Ω–æ–≥–æ –≥—Ä—É–∑–∞",
    "–ü–µ—Ä–µ–≤–æ–∑–∫–∞ —Ç—è–∂–µ–ª–æ–≤–µ—Å–Ω–æ–≥–æ –≥—Ä—É–∑–∞", "–ü–µ—Ä–µ–≤–æ–∑–∫–∞ –¥–æ—Ä–æ–≥–æ—Å—Ç–æ—è—â–µ–≥–æ –≥—Ä—É–∑–∞",
    "–ó–∞–∫—É–ø–∫–∞ —É –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –ø–æ—Å—Ç–∞–≤—â–∏–∫–∞",
]

RED_DOCUMENTS_ALWAYS = [
    "–ü—Ä–µ—Ç–µ–Ω–∑–∏—è (–≤—Ö–æ–¥—è—â–∞—è)", "–ü—Ä–µ—Ç–µ–Ω–∑–∏—è (–∏—Å—Ö–æ–¥—è—â–∞—è)",
    "–ò—Å–∫–æ–≤–æ–µ –∑–∞—è–≤–ª–µ–Ω–∏–µ", "–°—É–¥–µ–±–Ω—ã–π –ø—Ä–∏–∫–∞–∑",
    "–ó–∞–ø—Ä–æ—Å –§–ù–°", "–ó–∞–ø—Ä–æ—Å –§–ê–°", "–ó–∞–ø—Ä–æ—Å –ü—Ä–æ–∫—É—Ä–∞—Ç—É—Ä—ã",
    "–ó–∞–ø—Ä–æ—Å –†–æ—Å—Ç—Ä–∞–Ω—Å–Ω–∞–¥–∑–æ—Ä–∞", "–ó–∞–ø—Ä–æ—Å –ì–ò–¢ (—Ç—Ä—É–¥–æ–≤–∞—è –∏–Ω—Å–ø–µ–∫—Ü–∏—è)",
    "–ó–∞–ø—Ä–æ—Å –∏–Ω–æ–≥–æ –≥–æ—Å–æ—Ä–≥–∞–Ω–∞", "–ü—Ä–µ–¥–ø–∏—Å–∞–Ω–∏–µ –≥–æ—Å–æ—Ä–≥–∞–Ω–∞", "–¢—Ä–µ–±–æ–≤–∞–Ω–∏–µ –≥–æ—Å–æ—Ä–≥–∞–Ω–∞",
    "–î–¢–ü —Å —É—á–∞—Å—Ç–∏–µ–º –¢–° –∫–æ–º–ø–∞–Ω–∏–∏", "–£—Ç–µ—Ä—è –≥—Ä—É–∑–∞", "–ü–æ—Ä—á–∞ –≥—Ä—É–∑–∞",
    "–ü—Ä–æ—Å—Ç–æ–π, —Ç—Ä–µ–±—É—é—â–∏–π —é—Ä–∏–¥–∏—á–µ—Å–∫–æ–π —Ñ–∏–∫—Å–∞—Ü–∏–∏",
]

# ============================================================================
# –¢–ò–ü–û–í–´–ï –§–û–†–ú–´ (–í–°–¢–†–û–ï–ù–ù–´–ï)
# ============================================================================

BUILTIN_TYPICAL_FORMS = {
    "service": {
        "name": "–¢–∏–ø–æ–≤–∞—è —Ñ–æ—Ä–º–∞ –¥–æ–≥–æ–≤–æ—Ä–∞ –æ–∫–∞–∑–∞–Ω–∏—è —É—Å–ª—É–≥",
        "code": "–¢–§-–£–°–õ-001",
        "version": "3.0",
        "date": "01.01.2025",
        "sections": {
            "1. –ü–†–ï–î–ú–ï–¢ –î–û–ì–û–í–û–†–ê": {
                "required": True,
                "template": """1.1. –ò—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å –æ–±—è–∑—É–µ—Ç—Å—è –æ–∫–∞–∑–∞—Ç—å –ó–∞–∫–∞–∑—á–∏–∫—É —É—Å–ª—É–≥–∏, —É–∫–∞–∑–∞–Ω–Ω—ã–µ –≤ –¢–µ—Ö–Ω–∏—á–µ—Å–∫–æ–º –∑–∞–¥–∞–Ω–∏–∏ (–ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ ‚Ññ1), –∞ –ó–∞–∫–∞–∑—á–∏–∫ –æ–±—è–∑—É–µ—Ç—Å—è –ø—Ä–∏–Ω—è—Ç—å –∏ –æ–ø–ª–∞—Ç–∏—Ç—å –æ–∫–∞–∑–∞–Ω–Ω—ã–µ —É—Å–ª—É–≥–∏.""",
                "keywords": ["–ø—Ä–µ–¥–º–µ—Ç", "—É—Å–ª—É–≥–∏", "–æ–±—è–∑—É–µ—Ç—Å—è", "–æ–∫–∞–∑–∞—Ç—å", "–ø—Ä–∏–Ω—è—Ç—å", "–æ–ø–ª–∞—Ç–∏—Ç—å", "—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–µ –∑–∞–¥–∞–Ω–∏–µ"],
                "risk_patterns": []
            },
            "2. –°–¢–û–ò–ú–û–°–¢–¨ –ò –ü–û–†–Ø–î–û–ö –†–ê–°–ß–ï–¢–û–í": {
                "required": True,
                "template": """2.1. –°—Ç–æ–∏–º–æ—Å—Ç—å —É—Å–ª—É–≥ —Å–æ—Å—Ç–∞–≤–ª—è–µ—Ç _______ —Ä—É–±–ª–µ–π. 2.2. –û–ø–ª–∞—Ç–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç—Å—è –≤ —Ç–µ—á–µ–Ω–∏–µ 10 —Ä–∞–±–æ—á–∏—Ö –¥–Ω–µ–π —Å –¥–∞—Ç—ã –ø–æ–¥–ø–∏—Å–∞–Ω–∏—è –ê–∫—Ç–∞.""",
                "keywords": ["—Å—Ç–æ–∏–º–æ—Å—Ç—å", "–æ–ø–ª–∞—Ç–∞", "—Ä–∞–±–æ—á–∏—Ö –¥–Ω–µ–π", "–∞–∫—Ç", "–Ω–¥—Å", "—Ä–∞—Å—á–µ—Ç"],
                "risk_patterns": [
                    {"pattern": r"–ø—Ä–µ–¥–æ–ø–ª–∞—Ç.*(?:[3-9]\d|100)\s*%", "risk": "red", "issue": "–ü—Ä–µ–¥–æ–ø–ª–∞—Ç–∞ –±–æ–ª–µ–µ 30%"},
                    {"pattern": r"–æ–ø–ª–∞—Ç–∞.*(?:1|2|3)\s*(?:—Ä–∞–±–æ—á|–∫–∞–ª–µ–Ω–¥–∞—Ä–Ω)", "risk": "yellow", "issue": "–°–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π —Å—Ä–æ–∫ –æ–ø–ª–∞—Ç—ã"},
                ]
            },
            "3. –°–†–û–ö–ò –û–ö–ê–ó–ê–ù–ò–Ø –£–°–õ–£–ì": {
                "required": True,
                "template": """3.1. –°—Ä–æ–∫ –æ–∫–∞–∑–∞–Ω–∏—è —É—Å–ª—É–≥: —Å ¬´___¬ª ________ 202__ –≥. –ø–æ ¬´___¬ª ________ 202__ –≥.""",
                "keywords": ["—Å—Ä–æ–∫", "–æ–∫–∞–∑–∞–Ω–∏—è", "—É—Å–ª—É–≥", "–ø–µ—Ä–∏–æ–¥"],
                "risk_patterns": []
            },
            "4. –ü–û–†–Ø–î–û–ö –°–î–ê–ß–ò-–ü–†–ò–ï–ú–ö–ò –£–°–õ–£–ì": {
                "required": True,
                "template": """4.1. –ü–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏ –æ–∫–∞–∑–∞–Ω–∏—è —É—Å–ª—É–≥ –ò—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å –Ω–∞–ø—Ä–∞–≤–ª—è–µ—Ç –ó–∞–∫–∞–∑—á–∏–∫—É –ê–∫—Ç –≤ 2-—Ö —ç–∫–∑–µ–º–ø–ª—è—Ä–∞—Ö. 4.2. –ó–∞–∫–∞–∑—á–∏–∫ –≤ —Ç–µ—á–µ–Ω–∏–µ 5 —Ä–∞–±–æ—á–∏—Ö –¥–Ω–µ–π –æ–±—è–∑–∞–Ω –ø–æ–¥–ø–∏—Å–∞—Ç—å –µ–≥–æ –∏–ª–∏ –Ω–∞–ø—Ä–∞–≤–∏—Ç—å –º–æ—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç–∫–∞–∑.""",
                "keywords": ["–ø—Ä–∏–µ–º–∫–∞", "–∞–∫—Ç", "—Å–¥–∞—á–∞", "—Ä–∞–±–æ—á–∏—Ö –¥–Ω–µ–π", "–º–æ—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç–∫–∞–∑"],
                "risk_patterns": [
                    {"pattern": r"(?:1|2)\s*(?:—Ä–∞–±–æ—á|–∫–∞–ª–µ–Ω–¥–∞—Ä–Ω).*(?:–ø–æ–¥–ø–∏—Å|–ø—Ä–∏–Ω—è)", "risk": "yellow", "issue": "–°–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π —Å—Ä–æ–∫ –ø—Ä–∏–µ–º–∫–∏"},
                ]
            },
            "5. –ü–†–ê–í–ê –ò –û–ë–Ø–ó–ê–ù–ù–û–°–¢–ò –°–¢–û–†–û–ù": {
                "required": True,
                "template": """5.1. –ò—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å –æ–±—è–∑–∞–Ω –æ–∫–∞–∑–∞—Ç—å —É—Å–ª—É–≥–∏ –Ω–∞–¥–ª–µ–∂–∞—â–µ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞. 5.2. –ó–∞–∫–∞–∑—á–∏–∫ –æ–±—è–∑–∞–Ω —Å–≤–æ–µ–≤—Ä–µ–º–µ–Ω–Ω–æ –æ–ø–ª–∞—Ç–∏—Ç—å —É—Å–ª—É–≥–∏.""",
                "keywords": ["–ø—Ä–∞–≤–∞", "–æ–±—è–∑–∞–Ω–Ω–æ—Å—Ç–∏", "–∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å", "–∑–∞–∫–∞–∑—á–∏–∫", "–æ–±—è–∑–∞–Ω"],
                "risk_patterns": []
            },
            "6. –û–¢–í–ï–¢–°–¢–í–ï–ù–ù–û–°–¢–¨ –°–¢–û–†–û–ù": {
                "required": True,
                "template": """6.1. –ó–∞ –Ω–∞—Ä—É—à–µ–Ω–∏–µ —Å—Ä–æ–∫–æ–≤ –æ–ø–ª–∞—Ç—ã –Ω–µ—É—Å—Ç–æ–π–∫–∞ 0,1% –∑–∞ –∫–∞–∂–¥—ã–π –¥–µ–Ω—å –ø—Ä–æ—Å—Ä–æ—á–∫–∏, –Ω–æ –Ω–µ –±–æ–ª–µ–µ 10%. 6.2. –ó–∞ –Ω–∞—Ä—É—à–µ–Ω–∏–µ —Å—Ä–æ–∫–æ–≤ –æ–∫–∞–∑–∞–Ω–∏—è —É—Å–ª—É–≥ –Ω–µ—É—Å—Ç–æ–π–∫–∞ 0,1% –∑–∞ –∫–∞–∂–¥—ã–π –¥–µ–Ω—å –ø—Ä–æ—Å—Ä–æ—á–∫–∏, –Ω–æ –Ω–µ –±–æ–ª–µ–µ 10%.""",
                "keywords": ["–æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å", "–Ω–µ—É—Å—Ç–æ–π–∫–∞", "–ø—Ä–æ—Å—Ä–æ—á–∫–∞", "—à—Ç—Ä–∞—Ñ"],
                "risk_patterns": [
                    {"pattern": r"–æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç.*–æ–≥—Ä–∞–Ω–∏—á–µ–Ω.*(?:–ø–æ—Å–ª–µ–¥–Ω|–º–µ—Å—è—Ü|–ø–ª–∞—Ç–µ–∂)", "risk": "red", "issue": "–û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏ —Å—É–º–º–æ–π –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –ø–ª–∞—Ç–µ–∂–∞"},
                    {"pattern": r"–Ω–µ\s+(?:–Ω–µ—Å–µ—Ç|–æ—Ç–≤–µ—á–∞–µ—Ç).*(?:–∫–æ—Å–≤–µ–Ω–Ω|—É–ø—É—â–µ–Ω–Ω)", "risk": "red", "issue": "–ò—Å–∫–ª—é—á–µ–Ω–∏–µ –∫–æ—Å–≤–µ–Ω–Ω—ã—Ö —É–±—ã—Ç–∫–æ–≤"},
                    {"pattern": r"–Ω–µ—É—Å—Ç–æ–π–∫.*(?:0[,.]?[5-9]|[1-9][,.]?\d)\s*%", "risk": "red", "issue": "–ù–µ—É—Å—Ç–æ–π–∫–∞ –≤—ã—à–µ 0.3% –≤ –¥–µ–Ω—å"},
                    {"pattern": r"(?:–ø–æ–ª–Ω\w+|–Ω–µ–æ–≥—Ä–∞–Ω–∏—á–µ–Ω\w+).*–æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç", "risk": "red", "issue": "–ù–µ–æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–∞—è –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å"},
                ]
            },
            "7. –ö–û–ù–§–ò–î–ï–ù–¶–ò–ê–õ–¨–ù–û–°–¢–¨": {
                "required": True,
                "template": """7.1. –°—Ç–æ—Ä–æ–Ω—ã –æ–±—è–∑—É—é—Ç—Å—è –Ω–µ —Ä–∞–∑–≥–ª–∞—à–∞—Ç—å –∫–æ–Ω—Ñ–∏–¥–µ–Ω—Ü–∏–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤ —Ç–µ—á–µ–Ω–∏–µ 3 –ª–µ—Ç –ø–æ—Å–ª–µ –ø—Ä–µ–∫—Ä–∞—â–µ–Ω–∏—è –î–æ–≥–æ–≤–æ—Ä–∞.""",
                "keywords": ["–∫–æ–Ω—Ñ–∏–¥–µ–Ω—Ü–∏–∞–ª—å–Ω–æ—Å—Ç—å", "—Ä–∞–∑–≥–ª–∞—à–∞—Ç—å", "–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è", "—Å–µ–∫—Ä–µ—Ç"],
                "risk_patterns": [
                    {"pattern": r"(?:—à—Ç—Ä–∞—Ñ|–Ω–µ—É—Å—Ç–æ–π–∫).*–∫–æ–Ω—Ñ–∏–¥–µ–Ω—Ü–∏–∞–ª—å–Ω–æ—Å—Ç.*(?:[5-9]|1\d)\s*(?:000\s*000|–º–ª–Ω)", "risk": "red", "issue": "–ß—Ä–µ–∑–º–µ—Ä–Ω—ã–π —à—Ç—Ä–∞—Ñ –∑–∞ –∫–æ–Ω—Ñ–∏–¥–µ–Ω—Ü–∏–∞–ª—å–Ω–æ—Å—Ç—å (>5 –º–ª–Ω)"},
                ]
            },
            "8. –ò–ù–¢–ï–õ–õ–ï–ö–¢–£–ê–õ–¨–ù–ê–Ø –°–û–ë–°–¢–í–ï–ù–ù–û–°–¢–¨": {
                "required": False,
                "template": """8.1. –ò—Å–∫–ª—é—á–∏—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–∞–≤–∞ –Ω–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–µ—Ä–µ—Ö–æ–¥—è—Ç –∫ –ó–∞–∫–∞–∑—á–∏–∫—É —Å –º–æ–º–µ–Ω—Ç–∞ –ø–æ–¥–ø–∏—Å–∞–Ω–∏—è –ê–∫—Ç–∞.""",
                "keywords": ["–∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–∞—è", "—Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å", "–ø—Ä–∞–≤–∞", "—Ä–µ–∑—É–ª—å—Ç–∞—Ç", "–∏—Å–∫–ª—é—á–∏—Ç–µ–ª—å–Ω—ã–µ"],
                "risk_patterns": [
                    {"pattern": r"(?:–∏—Å–∫–ª—é—á–∏—Ç–µ–ª—å–Ω\w+\s+)?–ø—Ä–∞–≤\w+.*(?:–ø—Ä–∏–Ω–∞–¥–ª–µ–∂–∞—Ç?|–æ—Å—Ç–∞—é—Ç?—Å—è|–ø–µ—Ä–µ—Ö–æ–¥—è—Ç?).*–∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª", "risk": "red", "issue": "–ü—Ä–∞–≤–∞ –Ω–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—Å—Ç–∞—é—Ç—Å—è —É –ò—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—è"},
                    {"pattern": r"–Ω–µ–∏—Å–∫–ª—é—á–∏—Ç–µ–ª—å–Ω\w+\s+–ª–∏—Ü–µ–Ω–∑–∏", "risk": "yellow", "issue": "–¢–æ–ª—å–∫–æ –Ω–µ–∏—Å–∫–ª—é—á–∏—Ç–µ–ª—å–Ω–∞—è –ª–∏—Ü–µ–Ω–∑–∏—è –¥–ª—è –ó–∞–∫–∞–∑—á–∏–∫–∞"},
                ]
            },
            "9. –°–†–û–ö –î–ï–ô–°–¢–í–ò–Ø –ò –†–ê–°–¢–û–†–ñ–ï–ù–ò–ï": {
                "required": True,
                "template": """9.1. –î–æ–≥–æ–≤–æ—Ä –¥–µ–π—Å—Ç–≤—É–µ—Ç –¥–æ –ø–æ–ª–Ω–æ–≥–æ –∏—Å–ø–æ–ª–Ω–µ–Ω–∏—è –æ–±—è–∑–∞—Ç–µ–ª—å—Å—Ç–≤. 9.2. –õ—é–±–∞—è –°—Ç–æ—Ä–æ–Ω–∞ –≤–ø—Ä–∞–≤–µ —Ä–∞—Å—Ç–æ—Ä–≥–Ω—É—Ç—å –î–æ–≥–æ–≤–æ—Ä —Å —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ–º –∑–∞ 30 –¥–Ω–µ–π.""",
                "keywords": ["—Å—Ä–æ–∫", "–¥–µ–π—Å—Ç–≤–∏—è", "—Ä–∞—Å—Ç–æ—Ä–∂–µ–Ω–∏–µ", "—É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ", "–æ–¥–Ω–æ—Å—Ç–æ—Ä–æ–Ω–Ω"],
                "risk_patterns": [
                    {"pattern": r"–∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å.*(?:–≤–ø—Ä–∞–≤–µ|–∏–º–µ–µ—Ç\s+–ø—Ä–∞–≤–æ).*–æ–¥–Ω–æ—Å—Ç–æ—Ä–æ–Ω–Ω.*—Ä–∞—Å—Ç–æ—Ä–≥.*(?:[1-9]|1[0-4])\s*(?:–¥–Ω|–∫–∞–ª–µ–Ω–¥–∞—Ä–Ω)", "risk": "red", "issue": "–û–¥–Ω–æ—Å—Ç–æ—Ä–æ–Ω–Ω–∏–π –æ—Ç–∫–∞–∑ –ò—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—è —Å –∫–æ—Ä–æ—Ç–∫–∏–º —Å—Ä–æ–∫–æ–º (<15 –¥–Ω–µ–π)"},
                    {"pattern": r"–∑–∞–∫–∞–∑—á–∏–∫.*—Ç–æ–ª—å–∫–æ.*(?:—Å—É—â–µ—Å—Ç–≤–µ–Ω–Ω|–Ω–∞—Ä—É—à–µ–Ω)", "risk": "red", "issue": "–û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –ø—Ä–∞–≤–∞ –ó–∞–∫–∞–∑—á–∏–∫–∞ –Ω–∞ —Ä–∞—Å—Ç–æ—Ä–∂–µ–Ω–∏–µ"},
                    {"pattern": r"–∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫\w+\s+(?:–ø—Ä–æ–ª–æ–Ω–≥–∞—Ü|–ø—Ä–æ–¥–ª–µ–Ω)", "risk": "yellow", "issue": "–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –ø—Ä–æ–ª–æ–Ω–≥–∞—Ü–∏—è"},
                ]
            },
            "10. –†–ê–ó–†–ï–®–ï–ù–ò–ï –°–ü–û–†–û–í": {
                "required": True,
                "template": """10.1. –°–ø–æ—Ä—ã —Ä–∞–∑—Ä–µ—à–∞—é—Ç—Å—è –ø—É—Ç–µ–º –ø–µ—Ä–µ–≥–æ–≤–æ—Ä–æ–≤. 10.2. –ü—Ä–∏ –Ω–µ–¥–æ—Å—Ç–∏–∂–µ–Ω–∏–∏ —Å–æ–≥–ª–∞—Å–∏—è ‚Äî –≤ –ê—Ä–±–∏—Ç—Ä–∞–∂–Ω–æ–º —Å—É–¥–µ –≥. –ú–æ—Å–∫–≤—ã.""",
                "keywords": ["—Å–ø–æ—Ä—ã", "–∞—Ä–±–∏—Ç—Ä–∞–∂–Ω—ã–π", "—Å—É–¥", "—Ä–∞–∑–Ω–æ–≥–ª–∞—Å–∏—è", "–ø–µ—Ä–µ–≥–æ–≤–æ—Ä—ã"],
                "risk_patterns": [
                    {"pattern": r"–∞—Ä–±–∏—Ç—Ä–∞–∂–Ω\w+\s+—Å—É–¥\w*.*(?:—Å–∞–Ω–∫—Ç-–ø–µ—Ç–µ—Ä–±—É—Ä–≥|—Å–ø–±|–ø–∏—Ç–µ—Ä)", "risk": "yellow", "issue": "–ü–æ–¥—Å—É–¥–Ω–æ—Å—Ç—å –≤ –°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥–µ"},
                    {"pattern": r"—Ç—Ä–µ—Ç–µ–π—Å–∫\w+\s+—Å—É–¥", "risk": "yellow", "issue": "–¢—Ä–µ—Ç–µ–π—Å–∫–∞—è –æ–≥–æ–≤–æ—Ä–∫–∞"},
                ]
            },
            "11. –§–û–†–°-–ú–ê–ñ–û–†": {
                "required": True,
                "template": """11.1. –°—Ç–æ—Ä–æ–Ω—ã –æ—Å–≤–æ–±–æ–∂–¥–∞—é—Ç—Å—è –æ—Ç –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏ –ø—Ä–∏ –æ–±—Å—Ç–æ—è—Ç–µ–ª—å—Å—Ç–≤–∞—Ö –Ω–µ–ø—Ä–µ–æ–¥–æ–ª–∏–º–æ–π —Å–∏–ª—ã.""",
                "keywords": ["—Ñ–æ—Ä—Å-–º–∞–∂–æ—Ä", "–Ω–µ–ø—Ä–µ–æ–¥–æ–ª–∏–º–æ–π —Å–∏–ª—ã", "–æ–±—Å—Ç–æ—è—Ç–µ–ª—å—Å—Ç–≤–∞"],
                "risk_patterns": []
            },
            "12. –ó–ê–ö–õ–Æ–ß–ò–¢–ï–õ–¨–ù–´–ï –ü–û–õ–û–ñ–ï–ù–ò–Ø": {
                "required": True,
                "template": """12.1. –î–æ–≥–æ–≤–æ—Ä —Å–æ—Å—Ç–∞–≤–ª–µ–Ω –≤ –¥–≤—É—Ö —ç–∫–∑–µ–º–ø–ª—è—Ä–∞—Ö. 12.2. –ü—Ä–∏–ª–æ–∂–µ–Ω–∏—è —è–≤–ª—è—é—Ç—Å—è –Ω–µ–æ—Ç—ä–µ–º–ª–µ–º–æ–π —á–∞—Å—Ç—å—é –î–æ–≥–æ–≤–æ—Ä–∞.""",
                "keywords": ["–∑–∞–∫–ª—é—á–∏—Ç–µ–ª—å–Ω—ã–µ", "—ç–∫–∑–µ–º–ø–ª—è—Ä", "–ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è", "–∏–∑–º–µ–Ω–µ–Ω–∏—è"],
                "risk_patterns": []
            },
            "13. –†–ï–ö–í–ò–ó–ò–¢–´ –ò –ü–û–î–ü–ò–°–ò –°–¢–û–†–û–ù": {
                "required": True,
                "template": """–ó–ê–ö–ê–ó–ß–ò–ö: –ê–û ¬´–ù–ü–ö¬ª... –ò–°–ü–û–õ–ù–ò–¢–ï–õ–¨: ...""",
                "keywords": ["—Ä–µ–∫–≤–∏–∑–∏—Ç—ã", "–ø–æ–¥–ø–∏—Å–∏", "–∑–∞–∫–∞–∑—á–∏–∫", "–∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å", "–∏–Ω–Ω", "–∞–¥—Ä–µ—Å"],
                "risk_patterns": []
            }
        },
        "global_risk_patterns": [
            {"pattern": r"–æ–¥–Ω–æ—Å—Ç–æ—Ä–æ–Ω–Ω\w+.*–∏–∑–º–µ–Ω–µ–Ω\w+.*(?:—Ü–µ–Ω|—Å—Ç–æ–∏–º–æ—Å—Ç|—Ç–∞—Ä–∏—Ñ)", "risk": "red", "issue": "–û–¥–Ω–æ—Å—Ç–æ—Ä–æ–Ω–Ω–µ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ —Ü–µ–Ω—ã –∫–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç–æ–º"},
            {"pattern": r"—Å—É–±–ø–æ–¥—Ä—è–¥.*–±–µ–∑.*(?:—Å–æ–≥–ª–∞—Å–∏|—É–≤–µ–¥–æ–º–ª–µ–Ω–∏)", "risk": "yellow", "issue": "–°—É–±–ø–æ–¥—Ä—è–¥ –±–µ–∑ —Å–æ–≥–ª–∞—Å–∏—è –ó–∞–∫–∞–∑—á–∏–∫–∞"},
            {"pattern": r"(?:usd|eur|–µ–≤—Ä–æ|–¥–æ–ª–ª–∞—Ä|–≤–∞–ª—é—Ç|—É\.–µ\.)", "risk": "yellow", "issue": "–í–∞–ª—é—Ç–Ω–∞—è –æ–≥–æ–≤–æ—Ä–∫–∞"},
        ]
    },
    "supply": {
        "name": "–¢–∏–ø–æ–≤–∞—è —Ñ–æ—Ä–º–∞ –¥–æ–≥–æ–≤–æ—Ä–∞ –ø–æ—Å—Ç–∞–≤–∫–∏",
        "code": "–¢–§-–ü–û–°-001",
        "version": "2.0",
        "date": "01.01.2025",
        "sections": {
            "1. –ü–†–ï–î–ú–ï–¢ –î–û–ì–û–í–û–†–ê": {"required": True, "template": "–ü–æ—Å—Ç–∞–≤—â–∏–∫ –æ–±—è–∑—É–µ—Ç—Å—è –ø–µ—Ä–µ–¥–∞—Ç—å —Ç–æ–≤–∞—Ä.", "keywords": ["–ø—Ä–µ–¥–º–µ—Ç", "–ø–æ—Å—Ç–∞–≤—â–∏–∫", "–ø–æ–∫—É–ø–∞—Ç–µ–ª—å", "—Ç–æ–≤–∞—Ä"], "risk_patterns": []},
            "2. –ö–ê–ß–ï–°–¢–í–û –ò –ö–û–ú–ü–õ–ï–ö–¢–ù–û–°–¢–¨": {"required": True, "template": "–ö–∞—á–µ—Å—Ç–≤–æ –ø–æ –ì–û–°–¢.", "keywords": ["–∫–∞—á–µ—Å—Ç–≤–æ", "–∫–æ–º–ø–ª–µ–∫—Ç–Ω–æ—Å—Ç—å", "–≥–æ—Å—Ç"], "risk_patterns": []},
            "3. –¶–ï–ù–ê –ò –†–ê–°–ß–ï–¢–´": {"required": True, "template": "–¶–µ–Ω–∞ –≤ –°–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏–∏.", "keywords": ["—Ü–µ–Ω–∞", "–æ–ø–ª–∞—Ç–∞", "—Ä–∞—Å—á–µ—Ç"], "risk_patterns": [{"pattern": r"–ø—Ä–µ–¥–æ–ø–ª–∞—Ç.*(?:[3-9]\d|100)\s*%", "risk": "red", "issue": "–ü—Ä–µ–¥–æ–ø–ª–∞—Ç–∞ –±–æ–ª–µ–µ 30%"}]},
            "4. –°–†–û–ö–ò –ü–û–°–¢–ê–í–ö–ò": {"required": True, "template": "–ü–æ—Å—Ç–∞–≤–∫–∞ –ø–æ –≥—Ä–∞—Ñ–∏–∫—É.", "keywords": ["—Å—Ä–æ–∫", "–ø–æ—Å—Ç–∞–≤–∫–∞"], "risk_patterns": []},
            "5. –ü–û–†–Ø–î–û–ö –ü–†–ò–ï–ú–ö–ò": {"required": True, "template": "–ü—Ä–∏–µ–º–∫–∞ –ø–æ –ü-6, –ü-7.", "keywords": ["–ø—Ä–∏–µ–º–∫–∞", "–ø-6", "–ø-7"], "risk_patterns": []},
            "6. –û–¢–í–ï–¢–°–¢–í–ï–ù–ù–û–°–¢–¨": {"required": True, "template": "–ù–µ—É—Å—Ç–æ–π–∫–∞ 0,1%.", "keywords": ["–æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å", "–Ω–µ—É—Å—Ç–æ–π–∫–∞"], "risk_patterns": []},
            "7. –ì–ê–†–ê–ù–¢–ò–ò": {"required": True, "template": "–ì–∞—Ä–∞–Ω—Ç–∏–π–Ω—ã–π —Å—Ä–æ–∫.", "keywords": ["–≥–∞—Ä–∞–Ω—Ç–∏—è"], "risk_patterns": []},
            "8. –§–û–†–°-–ú–ê–ñ–û–†": {"required": True, "template": "–ù–µ–ø—Ä–µ–æ–¥–æ–ª–∏–º–∞—è —Å–∏–ª–∞.", "keywords": ["—Ñ–æ—Ä—Å-–º–∞–∂–æ—Ä"], "risk_patterns": []},
            "9. –°–ü–û–†–´": {"required": True, "template": "–ê—Ä–±–∏—Ç—Ä–∞–∂ –ú–æ—Å–∫–≤—ã.", "keywords": ["—Å–ø–æ—Ä—ã", "–∞—Ä–±–∏—Ç—Ä–∞–∂–Ω—ã–π"], "risk_patterns": []},
            "10. –†–ï–ö–í–ò–ó–ò–¢–´": {"required": True, "template": "–†–µ–∫–≤–∏–∑–∏—Ç—ã —Å—Ç–æ—Ä–æ–Ω.", "keywords": ["—Ä–µ–∫–≤–∏–∑–∏—Ç—ã", "–ø–æ–¥–ø–∏—Å–∏"], "risk_patterns": []}
        },
        "global_risk_patterns": [{"pattern": r"–ø–µ—Ä–µ—Ö–æ–¥.*—Ä–∏—Å–∫.*–¥–æ.*–ø–µ—Ä–µ–¥–∞—á", "risk": "red", "issue": "–ü–µ—Ä–µ—Ö–æ–¥ —Ä–∏—Å–∫–æ–≤ –¥–æ –ø–µ—Ä–µ–¥–∞—á–∏ —Ç–æ–≤–∞—Ä–∞"}]
    },
    "wagon_rent": {
        "name": "–¢–∏–ø–æ–≤–∞—è —Ñ–æ—Ä–º–∞ –¥–æ–≥–æ–≤–æ—Ä–∞ –∞—Ä–µ–Ω–¥—ã –≤–∞–≥–æ–Ω–æ–≤",
        "code": "–¢–§-–ê–†–í-001",
        "version": "2.0",
        "date": "01.01.2025",
        "sections": {
            "1. –ü–†–ï–î–ú–ï–¢ –î–û–ì–û–í–û–†–ê": {"required": True, "template": "–ê—Ä–µ–Ω–¥–∞ –≤–∞–≥–æ–Ω–æ–≤.", "keywords": ["–ø—Ä–µ–¥–º–µ—Ç", "–∞—Ä–µ–Ω–¥–æ–¥–∞—Ç–µ–ª—å", "–∞—Ä–µ–Ω–¥–∞—Ç–æ—Ä", "–≤–∞–≥–æ–Ω"], "risk_patterns": []},
            "2. –ü–ï–†–ï–ß–ï–ù–¨ –í–ê–ì–û–ù–û–í": {"required": True, "template": "–°–ø–∏—Å–æ–∫ –≤–∞–≥–æ–Ω–æ–≤.", "keywords": ["–ø–µ—Ä–µ—á–µ–Ω—å", "–Ω–æ–º–µ—Ä", "–≤–∞–≥–æ–Ω"], "risk_patterns": []},
            "3. –ê–†–ï–ù–î–ù–ê–Ø –ü–õ–ê–¢–ê": {"required": True, "template": "–°—Ç–∞–≤–∫–∞ –∑–∞ —Å—É—Ç–∫–∏.", "keywords": ["–∞—Ä–µ–Ω–¥–∞", "—Å—Ç–∞–≤–∫–∞", "–ø–ª–∞—Ç–∞"], "risk_patterns": []},
            "4. –ü–ï–†–ï–î–ê–ß–ê –ò –í–û–ó–í–†–ê–¢": {"required": True, "template": "–ê–∫—Ç –ø–µ—Ä–µ–¥–∞—á–∏.", "keywords": ["–ø–µ—Ä–µ–¥–∞—á–∞", "–≤–æ–∑–≤—Ä–∞—Ç", "–∞–∫—Ç"], "risk_patterns": []},
            "5. –û–ë–Ø–ó–ê–ù–ù–û–°–¢–ò –ê–†–ï–ù–î–ê–¢–û–†–ê": {"required": True, "template": "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–æ –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—é.", "keywords": ["–æ–±—è–∑–∞–Ω–Ω–æ—Å—Ç–∏", "–∞—Ä–µ–Ω–¥–∞—Ç–æ—Ä"], "risk_patterns": []},
            "6. –û–¢–í–ï–¢–°–¢–í–ï–ù–ù–û–°–¢–¨": {"required": True, "template": "–û—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å –∑–∞ —É—Ç—Ä–∞—Ç—É.", "keywords": ["–æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å", "—Å–æ—Ö—Ä–∞–Ω–Ω–æ—Å—Ç—å", "—É—Ç—Ä–∞—Ç–∞"], "risk_patterns": [
                {"pattern": r"(?:–ø–æ–ª–Ω\w+|–Ω–µ–æ–≥—Ä–∞–Ω–∏—á–µ–Ω\w+).*–æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç.*—É—Ç—Ä–∞—Ç", "risk": "red", "issue": "–ù–µ–æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–∞—è –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å –∑–∞ —É—Ç—Ä–∞—Ç—É"},
                {"pattern": r"—à—Ç—Ä–∞—Ñ.*–ø—Ä–æ—Å—Ç–æ–π.*(?:[2-9]\d{3}|[1-9]\d{4})", "risk": "red", "issue": "–®—Ç—Ä–∞—Ñ –∑–∞ –ø—Ä–æ—Å—Ç–æ–π –±–æ–ª–µ–µ 2000 —Ä—É–±/—Å—É—Ç–∫–∏"}
            ]},
            "7. –°–¢–†–ê–•–û–í–ê–ù–ò–ï": {"required": True, "template": "–°—Ç—Ä–∞—Ö–æ–≤–∫–∞.", "keywords": ["—Å—Ç—Ä–∞—Ö–æ–≤–∞–Ω–∏–µ"], "risk_patterns": []},
            "8. –°–†–û–ö –ê–†–ï–ù–î–´": {"required": True, "template": "–°—Ä–æ–∫ –∞—Ä–µ–Ω–¥—ã.", "keywords": ["—Å—Ä–æ–∫", "–∞—Ä–µ–Ω–¥–∞"], "risk_patterns": []},
            "9. –°–ü–û–†–´": {"required": True, "template": "–ê—Ä–±–∏—Ç—Ä–∞–∂.", "keywords": ["—Å–ø–æ—Ä—ã", "–∞—Ä–±–∏—Ç—Ä–∞–∂–Ω—ã–π"], "risk_patterns": []},
            "10. –†–ï–ö–í–ò–ó–ò–¢–´": {"required": True, "template": "–†–µ–∫–≤–∏–∑–∏—Ç—ã.", "keywords": ["—Ä–µ–∫–≤–∏–∑–∏—Ç—ã", "–ø–æ–¥–ø–∏—Å–∏"], "risk_patterns": []}
        },
        "global_risk_patterns": []
    },
    "it_services": {
        "name": "–¢–∏–ø–æ–≤–∞—è —Ñ–æ—Ä–º–∞ –¥–æ–≥–æ–≤–æ—Ä–∞ –Ω–∞ IT-—É—Å–ª—É–≥–∏",
        "code": "–¢–§-–ò–¢-001",
        "version": "1.0",
        "date": "01.01.2025",
        "sections": {
            "1. –ü–†–ï–î–ú–ï–¢": {"required": True, "template": "IT-—É—Å–ª—É–≥–∏.", "keywords": ["–ø—Ä–µ–¥–º–µ—Ç", "it", "—É—Å–ª—É–≥–∏"], "risk_patterns": []},
            "2. SLA": {"required": True, "template": "–£—Ä–æ–≤–µ–Ω—å —Å–µ—Ä–≤–∏—Å–∞.", "keywords": ["sla", "—É—Ä–æ–≤–µ–Ω—å", "—Å–µ—Ä–≤–∏—Å"], "risk_patterns": [{"pattern": r"(?:–Ω–µ—Ç|–æ—Ç—Å—É—Ç—Å—Ç–≤|–±–µ–∑).*sla", "risk": "red", "issue": "–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç SLA"}]},
            "3. –°–¢–û–ò–ú–û–°–¢–¨": {"required": True, "template": "–°—Ç–æ–∏–º–æ—Å—Ç—å.", "keywords": ["—Å—Ç–æ–∏–º–æ—Å—Ç—å", "–æ–ø–ª–∞—Ç–∞"], "risk_patterns": []},
            "4. –ü–†–ê–í–ê –ù–ê –†–ï–ó–£–õ–¨–¢–ê–¢–´": {"required": True, "template": "–ü—Ä–∞–≤–∞.", "keywords": ["–ø—Ä–∞–≤–∞", "—Ä–µ–∑—É–ª—å—Ç–∞—Ç"], "risk_patterns": [{"pattern": r"–ø—Ä–∞–≤\w+.*(?:–ø—Ä–∏–Ω–∞–¥–ª–µ–∂–∞—Ç?|–æ—Å—Ç–∞—é—Ç?—Å—è).*–∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª", "risk": "red", "issue": "–ü—Ä–∞–≤–∞ –Ω–∞ –ü–û —É –ò—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—è"}]},
            "5. –ó–ê–©–ò–¢–ê –î–ê–ù–ù–´–•": {"required": True, "template": "152-–§–ó.", "keywords": ["–∑–∞—â–∏—Ç–∞", "–¥–∞–Ω–Ω—ã–µ", "–ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã–µ"], "risk_patterns": []},
            "6. –ü–û–î–î–ï–†–ñ–ö–ê": {"required": True, "template": "–ü–æ–¥–¥–µ—Ä–∂–∫–∞.", "keywords": ["–ø–æ–¥–¥–µ—Ä–∂–∫–∞"], "risk_patterns": []},
            "7. –û–¢–í–ï–¢–°–¢–í–ï–ù–ù–û–°–¢–¨": {"required": True, "template": "–û—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å.", "keywords": ["–æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å"], "risk_patterns": []},
            "8. –°–†–û–ö –ò –†–ê–°–¢–û–†–ñ–ï–ù–ò–ï": {"required": True, "template": "–°—Ä–æ–∫.", "keywords": ["—Å—Ä–æ–∫", "—Ä–∞—Å—Ç–æ—Ä–∂–µ–Ω–∏–µ"], "risk_patterns": []},
            "9. –†–ï–ö–í–ò–ó–ò–¢–´": {"required": True, "template": "–†–µ–∫–≤–∏–∑–∏—Ç—ã.", "keywords": ["—Ä–µ–∫–≤–∏–∑–∏—Ç—ã", "–ø–æ–¥–ø–∏—Å–∏"], "risk_patterns": []}
        },
        "global_risk_patterns": []
    }
}

# ============================================================================
# –ó–ê–ì–†–£–ó–ß–ò–ö –î–û–ö–£–ú–ï–ù–¢–û–í
# ============================================================================

class DocumentLoader:
    """–ó–∞–≥—Ä—É–∑—á–∏–∫ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤"""
    
    @classmethod
    def load_txt(cls, file_content: bytes) -> str:
        """–ó–∞–≥—Ä—É–∑–∫–∞ TXT —Ñ–∞–π–ª–∞"""
        encodings = ['utf-8', 'cp1251', 'latin-1']
        for enc in encodings:
            try:
                return file_content.decode(enc)
            except:
                continue
        return file_content.decode('utf-8', errors='ignore')
    
    @classmethod
    def load_docx(cls, file_content: bytes) -> str:
        """–ó–∞–≥—Ä—É–∑–∫–∞ DOCX —Ñ–∞–π–ª–∞"""
        try:
            from docx import Document
            doc = Document(io.BytesIO(file_content))
            text_parts = []
            for para in doc.paragraphs:
                if para.text.strip():
                    text_parts.append(para.text)
            # –¢–∞–±–ª–∏—Ü—ã
            for table in doc.tables:
                for row in table.rows:
                    row_text = [cell.text.strip() for cell in row.cells if cell.text.strip()]
                    if row_text:
                        text_parts.append(' | '.join(row_text))
            return '\n'.join(text_parts)
        except ImportError:
            return "–û—à–∏–±–∫–∞: —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ python-docx (pip install python-docx)"
        except Exception as e:
            return f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è DOCX: {str(e)}"
    
    @classmethod
    def load_pdf(cls, file_content: bytes) -> str:
        """–ó–∞–≥—Ä—É–∑–∫–∞ PDF —Ñ–∞–π–ª–∞"""
        try:
            from PyPDF2 import PdfReader
            reader = PdfReader(io.BytesIO(file_content))
            text_parts = []
            for page in reader.pages:
                text = page.extract_text()
                if text:
                    text_parts.append(text)
            return '\n'.join(text_parts)
        except ImportError:
            return "–û—à–∏–±–∫–∞: —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ PyPDF2 (pip install PyPDF2)"
        except Exception as e:
            return f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è PDF: {str(e)}"
    
    @classmethod
    def load_file(cls, uploaded_file) -> Tuple[bool, str]:
        """–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –∑–∞–≥—Ä—É–∑—á–∏–∫"""
        if not uploaded_file:
            return False, "–§–∞–π–ª –Ω–µ –≤—ã–±—Ä–∞–Ω"
        
        try:
            content = uploaded_file.read()
            filename = uploaded_file.name.lower()
            
            if filename.endswith('.txt'):
                text = cls.load_txt(content)
            elif filename.endswith('.docx'):
                text = cls.load_docx(content)
            elif filename.endswith('.pdf'):
                text = cls.load_pdf(content)
            else:
                return False, "–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç"
            
            if text.startswith("–û—à–∏–±–∫–∞"):
                return False, text
            
            return True, text
        except Exception as e:
            return False, f"–û—à–∏–±–∫–∞: {str(e)}"

# ============================================================================
# –ê–õ–ì–û–†–ò–¢–ú –°–†–ê–í–ù–ï–ù–ò–Ø
# ============================================================================

class AdvancedComparator:
    """–£–ª—É—á—à–µ–Ω–Ω—ã–π –∞–ª–≥–æ—Ä–∏—Ç–º —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –¥–æ–≥–æ–≤–æ—Ä–æ–≤"""
    
    STOP_WORDS = {'–∏', '–≤', '–Ω–∞', '–ø–æ', '—Å', '–∫', '–æ', '–æ—Ç', '–∏–∑', '–∑–∞', '–¥–ª—è', '–Ω–µ', '—á—Ç–æ', 
                  '–∫–∞–∫', '—ç—Ç–æ', '–≤—Å–µ', '–∏–ª–∏', '–ø—Ä–∏', '–¥–æ', '–±–µ–∑', '–µ–≥–æ', '–µ—ë', '–∏—Ö', '–±—ã—Ç—å',
                  '–∫–æ—Ç–æ—Ä—ã–π', '—Ç–∞–∫–∂–µ', '–º–µ–∂–¥—É', '–ø–æ—Å–ª–µ', '–ø–µ—Ä–µ–¥', '—á–µ—Ä–µ–∑', '–±–æ–ª–µ–µ', '–º–µ–Ω–µ–µ',
                  '–∞', '–Ω–æ', '–¥–∞', '–∂–µ', '–ª–∏', '–±—ã', '—Ç–æ', '–Ω–∏', '–µ—Å–ª–∏', '—á–µ–º'}
    
    @classmethod
    def tokenize(cls, text: str) -> List[str]:
        if not text:
            return []
        text = text.lower()
        text = re.sub(r'[^\w\s–∞-—è—ë]', ' ', text)
        tokens = text.split()
        return [t for t in tokens if len(t) > 2 and t not in cls.STOP_WORDS]
    
    @classmethod
    def get_ngrams(cls, tokens: List[str], n: int = 2) -> Set[Tuple]:
        if len(tokens) < n:
            return set()
        return set(tuple(tokens[i:i+n]) for i in range(len(tokens) - n + 1))
    
    @classmethod
    def jaccard_similarity(cls, set1: Set, set2: Set) -> float:
        if not set1 or not set2:
            return 0.0
        intersection = len(set1 & set2)
        union = len(set1 | set2)
        return intersection / union if union > 0 else 0.0
    
    @classmethod
    def overlap_coefficient(cls, set1: Set, set2: Set) -> float:
        if not set1 or not set2:
            return 0.0
        intersection = len(set1 & set2)
        min_size = min(len(set1), len(set2))
        return intersection / min_size if min_size > 0 else 0.0
    
    @classmethod
    def levenshtein_ratio(cls, s1: str, s2: str) -> float:
        if not s1 or not s2:
            return 0.0
        return difflib.SequenceMatcher(None, s1.lower(), s2.lower()).ratio()
    
    @classmethod
    def compute_tf(cls, tokens: List[str]) -> Dict[str, float]:
        if not tokens:
            return {}
        counter = Counter(tokens)
        total = len(tokens)
        return {k: v / total for k, v in counter.items()}
    
    @classmethod
    def compute_idf(cls, documents: List[List[str]]) -> Dict[str, float]:
        if not documents:
            return {}
        n_docs = len(documents)
        df = Counter()
        for doc in documents:
            for token in set(doc):
                df[token] += 1
        return {token: math.log((n_docs + 1) / (count + 1)) + 1 for token, count in df.items()}
    
    @classmethod
    def cosine_similarity(cls, vec1: Dict[str, float], vec2: Dict[str, float]) -> float:
        if not vec1 or not vec2:
            return 0.0
        all_keys = set(vec1.keys()) | set(vec2.keys())
        dot_product = sum(vec1.get(k, 0) * vec2.get(k, 0) for k in all_keys)
        norm1 = math.sqrt(sum(v ** 2 for v in vec1.values()))
        norm2 = math.sqrt(sum(v ** 2 for v in vec2.values()))
        return dot_product / (norm1 * norm2) if norm1 > 0 and norm2 > 0 else 0.0
    
    @classmethod
    def keyword_match_score(cls, text: str, keywords: List[str]) -> Tuple[float, List[str]]:
        if not keywords:
            return 0.0, []
        text_lower = text.lower()
        matched = [kw for kw in keywords if kw.lower() in text_lower]
        return len(matched) / len(keywords), matched
    
    @classmethod
    def extract_sections(cls, text: str) -> Dict[str, str]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ä–∞–∑–¥–µ–ª–æ–≤ –∏–∑ —Ç–µ–∫—Å—Ç–∞ –¥–æ–≥–æ–≤–æ—Ä–∞"""
        sections = {}
        patterns = [
            r'(\d+)\.\s*([–ê-–Ø–ÅA-Z][–ê-–Ø–ÅA-Z\s\-]+?)(?:\n|$)',
            r'(–†–ê–ó–î–ï–õ\s+\d+)[.\s]+(.+?)(?:\n|$)',
            r'(–°—Ç–∞—Ç—å—è\s+\d+)[.\s]+(.+?)(?:\n|$)',
        ]
        
        text_lines = text.split('\n')
        current_section = "–ü–†–ï–ê–ú–ë–£–õ–ê"
        current_content = []
        
        for line in text_lines:
            found_section = False
            for pattern in patterns:
                match = re.match(pattern, line.strip(), re.IGNORECASE)
                if match:
                    if current_content:
                        sections[current_section] = '\n'.join(current_content).strip()
                    current_section = f"{match.group(1)}. {match.group(2)}".strip().upper()
                    current_content = [line]
                    found_section = True
                    break
            
            if not found_section:
                current_content.append(line)
        
        if current_content:
            sections[current_section] = '\n'.join(current_content).strip()
        
        return sections
    
    @classmethod
    def compare_section(cls, contract_section: str, template_section: str, keywords: List[str]) -> Dict:
        result = {
            "found": False,
            "similarity_scores": {},
            "combined_score": 0,
            "matched_keywords": [],
            "keyword_score": 0,
            "deviations": [],
            "status": "missing"
        }
        
        if not contract_section:
            return result
        
        result["found"] = True
        
        contract_tokens = cls.tokenize(contract_section)
        template_tokens = cls.tokenize(template_section)
        
        contract_set = set(contract_tokens)
        template_set = set(template_tokens)
        jaccard = cls.jaccard_similarity(contract_set, template_set)
        result["similarity_scores"]["jaccard_words"] = jaccard
        
        contract_bigrams = cls.get_ngrams(contract_tokens, 2)
        template_bigrams = cls.get_ngrams(template_tokens, 2)
        jaccard_bigrams = cls.jaccard_similarity(contract_bigrams, template_bigrams)
        result["similarity_scores"]["jaccard_bigrams"] = jaccard_bigrams
        
        overlap = cls.overlap_coefficient(contract_set, template_set)
        result["similarity_scores"]["overlap"] = overlap
        
        levenshtein = cls.levenshtein_ratio(contract_section[:1000], template_section[:1000])
        result["similarity_scores"]["levenshtein"] = levenshtein
        
        docs = [contract_tokens, template_tokens]
        idf = cls.compute_idf(docs)
        contract_tfidf = {k: cls.compute_tf(contract_tokens).get(k, 0) * idf.get(k, 1) for k in contract_set}
        template_tfidf = {k: cls.compute_tf(template_tokens).get(k, 0) * idf.get(k, 1) for k in template_set}
        cosine = cls.cosine_similarity(contract_tfidf, template_tfidf)
        result["similarity_scores"]["cosine_tfidf"] = cosine
        
        keyword_score, matched = cls.keyword_match_score(contract_section, keywords)
        result["keyword_score"] = keyword_score
        result["matched_keywords"] = matched
        
        weights = {"jaccard_words": 0.15, "jaccard_bigrams": 0.20, "overlap": 0.15, 
                   "levenshtein": 0.20, "cosine_tfidf": 0.15, "keywords": 0.15}
        
        combined = (jaccard * weights["jaccard_words"] + jaccard_bigrams * weights["jaccard_bigrams"] +
                    overlap * weights["overlap"] + levenshtein * weights["levenshtein"] +
                    cosine * weights["cosine_tfidf"] + keyword_score * weights["keywords"])
        result["combined_score"] = combined
        
        if combined >= 0.7:
            result["status"] = "match"
        elif combined >= 0.4:
            result["status"] = "partial"
        else:
            result["status"] = "deviation"
        
        return result
    
    @classmethod
    def find_best_matching_section(cls, section_name: str, contract_sections: Dict[str, str], 
                                   template_text: str, keywords: List[str]) -> Tuple[str, Dict]:
        best_match = None
        best_result = None
        best_score = 0
        
        section_name_normalized = re.sub(r'^\d+\.\s*', '', section_name).lower()
        
        for contract_section_name, contract_section_text in contract_sections.items():
            contract_name_normalized = re.sub(r'^\d+\.\s*', '', contract_section_name).lower()
            name_similarity = cls.levenshtein_ratio(section_name_normalized, contract_name_normalized)
            
            comparison = cls.compare_section(contract_section_text, template_text, keywords)
            
            total_score = comparison["combined_score"] * 0.7 + name_similarity * 0.3
            
            if total_score > best_score:
                best_score = total_score
                best_match = contract_section_name
                best_result = comparison
                best_result["matched_section_name"] = contract_section_name
                best_result["name_similarity"] = name_similarity
        
        return best_match, best_result
    
    @classmethod
    def check_risk_patterns(cls, text: str, patterns: List[Dict]) -> List[Dict]:
        found_risks = []
        text_lower = text.lower()
        
        for p in patterns:
            match = re.search(p["pattern"], text_lower)
            if match:
                start = max(0, match.start() - 100)
                end = min(len(text_lower), match.end() + 100)
                context = text_lower[start:end]
                
                found_risks.append({
                    "issue": p["issue"],
                    "risk_level": p.get("risk", "yellow"),
                    "context": f"...{context}...",
                    "position": match.start()
                })
        
        return found_risks
    
    @classmethod
    def full_comparison(cls, contract_text: str, typical_form: Dict) -> Dict:
        result = {
            "form_name": typical_form.get("name", ""),
            "form_code": typical_form.get("code", ""),
            "form_version": typical_form.get("version", ""),
            "sections_analysis": [],
            "missing_sections": [],
            "found_sections": [],
            "partial_sections": [],
            "deviation_sections": [],
            "risks": [],
            "global_risks": [],
            "compliance_score": 0,
            "section_scores": {},
            "recommendations": [],
            "summary": ""
        }
        
        contract_sections = cls.extract_sections(contract_text)
        
        total_score = 0
        total_weight = 0
        
        for section_name, section_data in typical_form.get("sections", {}).items():
            weight = 2.0 if section_data.get("required", False) else 1.0
            total_weight += weight
            
            matched_name, comparison = cls.find_best_matching_section(
                section_name, contract_sections,
                section_data.get("template", ""),
                section_data.get("keywords", [])
            )
            
            section_result = {
                "section_name": section_name,
                "required": section_data.get("required", False),
                "matched_in_contract": matched_name,
                "comparison": comparison if comparison else {"found": False, "combined_score": 0, "status": "missing"},
                "risks": []
            }
            
            if matched_name and contract_sections.get(matched_name):
                section_risks = cls.check_risk_patterns(
                    contract_sections[matched_name],
                    section_data.get("risk_patterns", [])
                )
                section_result["risks"] = section_risks
                result["risks"].extend(section_risks)
            
            if comparison and comparison.get("found"):
                if comparison.get("status") == "match":
                    result["found_sections"].append(section_name)
                    total_score += weight
                elif comparison.get("status") == "partial":
                    result["partial_sections"].append(section_name)
                    total_score += weight * 0.6
                else:
                    result["deviation_sections"].append(section_name)
                    total_score += weight * 0.3
                    result["recommendations"].append(f"–†–∞–∑–¥–µ–ª '{section_name}' —Å—É—â–µ—Å—Ç–≤–µ–Ω–Ω–æ –æ—Ç–ª–∏—á–∞–µ—Ç—Å—è –æ—Ç –¢–§")
            else:
                if section_data.get("required"):
                    result["missing_sections"].append(section_name)
                    result["recommendations"].append(f"–ö–†–ò–¢–ò–ß–ù–û: –û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–π —Ä–∞–∑–¥–µ–ª '{section_name}'")
                else:
                    result["missing_sections"].append(section_name)
            
            result["sections_analysis"].append(section_result)
            if comparison:
                result["section_scores"][section_name] = comparison.get("combined_score", 0)
        
        global_risks = cls.check_risk_patterns(contract_text, typical_form.get("global_risk_patterns", []))
        result["global_risks"] = global_risks
        result["risks"].extend(global_risks)
        
        red_risks = sum(1 for r in result["risks"] if r.get("risk_level") == "red")
        yellow_risks = sum(1 for r in result["risks"] if r.get("risk_level") == "yellow")
        risk_penalty = red_risks * 0.15 + yellow_risks * 0.05
        
        if total_weight > 0:
            base_score = (total_score / total_weight) * 100
            result["compliance_score"] = max(0, base_score - risk_penalty * 100)
        
        if result["compliance_score"] >= 80:
            result["summary"] = "–í—ã—Å–æ–∫–æ–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Ç–∏–ø–æ–≤–æ–π —Ñ–æ—Ä–º–µ."
        elif result["compliance_score"] >= 50:
            result["summary"] = "–ß–∞—Å—Ç–∏—á–Ω–æ–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ. –¢—Ä–µ–±—É–µ—Ç—Å—è –ø—Ä–æ–≤–µ—Ä–∫–∞."
        else:
            result["summary"] = "–°—É—â–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è. –¢—Ä–µ–±—É–µ—Ç—Å—è —ç–∫—Å–ø–µ—Ä—Ç–∏–∑–∞."
        
        return result

# ============================================================================
# AI –ê–ù–ê–õ–ò–ó–ê–¢–û–†
# ============================================================================

class AIAnalyzer:
    @classmethod
    def generate_risk_analysis_prompt(cls, contract_text: str, comparison_result: Dict) -> str:
        risks_text = ""
        for risk in comparison_result.get("risks", []):
            level = "üî¥ –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô" if risk.get("risk_level") == "red" else "üü° –í–ù–ò–ú–ê–ù–ò–ï"
            risks_text += f"\n- {level}: {risk.get('issue', '')}\n–ö–æ–Ω—Ç–µ–∫—Å—Ç: {risk.get('context', '')[:200]}\n"
        
        missing = ", ".join(comparison_result.get("missing_sections", [])) or "–ù–µ—Ç"
        deviations = ", ".join(comparison_result.get("deviation_sections", [])) or "–ù–µ—Ç"
        
        prompt = f"""–¢—ã ‚Äî –æ–ø—ã—Ç–Ω—ã–π —é—Ä–∏—Å—Ç –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–æ–≥–æ –ø—Ä–∞–≤–∞.

–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –¥–æ–≥–æ–≤–æ—Ä –¥–ª—è –ê–û ¬´–ù–ü–ö¬ª (–ó–∞–∫–∞–∑—á–∏–∫/–ü–æ–∫—É–ø–∞—Ç–µ–ª—å):

–î–û–ì–û–í–û–†:
{contract_text[:8000]}

–û–¢–ö–õ–û–ù–ï–ù–ò–Ø –û–¢ –¢–ò–ü–û–í–û–ô –§–û–†–ú–´:
- –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –¢–§: {comparison_result.get('compliance_score', 0):.0f}%
- –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ —Ä–∞–∑–¥–µ–ª—ã: {missing}
- –†–∞–∑–¥–µ–ª—ã —Å –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è–º–∏: {deviations}

–í–´–Ø–í–õ–ï–ù–ù–´–ï –†–ò–°–ö–ò:
{risks_text if risks_text else "–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –Ω–µ –≤—ã—è–≤–ª–µ–Ω—ã"}

–ù–∞–ø–∏—à–∏ —é—Ä–∏–¥–∏—á–µ—Å–∫–æ–µ –∑–∞–∫–ª—é—á–µ–Ω–∏–µ:

1. –ö–†–ê–¢–ö–û–ï –†–ï–ó–Æ–ú–ï (2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è)
2. –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ï –†–ò–°–ö–ò (—Ç—Ä–µ–±—É—é—Ç —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è)
3. –£–°–õ–û–í–ò–Ø, –¢–†–ï–ë–£–Æ–©–ò–ï –í–ù–ò–ú–ê–ù–ò–Ø
4. –û–¢–°–£–¢–°–¢–í–£–Æ–©–ò–ï –ó–ê–©–ò–¢–ù–´–ï –ú–ï–•–ê–ù–ò–ó–ú–´
5. –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –ü–û –ü–ï–†–ï–ì–û–í–û–†–ê–ú
6. –ò–¢–û–ì–û–í–û–ï –ó–ê–ö–õ–Æ–ß–ï–ù–ò–ï (—Å–æ–≥–ª–∞—Å–æ–≤–∞—Ç—å/–¥–æ—Ä–∞–±–æ—Ç–∞—Ç—å/–æ—Ç–∫–ª–æ–Ω–∏—Ç—å)
"""
        return prompt
    
    @classmethod
    def call_openai(cls, prompt: str, api_key: str) -> str:
        try:
            import requests
            response = requests.post(
                "https://api.openai.com/v1/chat/completions",
                headers={"Authorization": f"Bearer {api_key}", "Content-Type": "application/json"},
                json={"model": "gpt-4o-mini", "messages": [{"role": "user", "content": prompt}], "max_tokens": 4000},
                timeout=60
            )
            if response.status_code == 200:
                return response.json()["choices"][0]["message"]["content"]
            return f"–û—à–∏–±–∫–∞ API: {response.status_code}"
        except Exception as e:
            return f"–û—à–∏–±–∫–∞: {str(e)}"
    
    @classmethod
    def call_anthropic(cls, prompt: str, api_key: str) -> str:
        try:
            import requests
            response = requests.post(
                "https://api.anthropic.com/v1/messages",
                headers={"x-api-key": api_key, "Content-Type": "application/json", "anthropic-version": "2023-06-01"},
                json={"model": "claude-3-haiku-20240307", "max_tokens": 4000, "messages": [{"role": "user", "content": prompt}]},
                timeout=60
            )
            if response.status_code == 200:
                return response.json()["content"][0]["text"]
            return f"–û—à–∏–±–∫–∞ API: {response.status_code}"
        except Exception as e:
            return f"–û—à–∏–±–∫–∞: {str(e)}"

# ============================================================================
# –ì–ï–ù–ï–†–ê–¢–û–† –û–¢–ß–ï–¢–û–í
# ============================================================================

class ReportGenerator:
    """–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –æ—Ç—á–µ—Ç–æ–≤ –≤ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–∞—Ö"""
    
    @classmethod
    def generate_text_report(cls, data: Dict, user: Dict, ai_analysis: str = "") -> str:
        zone_names = {"green": "–ó–ï–õ–ï–ù–ê–Ø", "yellow": "–ñ–ï–õ–¢–ê–Ø", "red": "–ö–†–ê–°–ù–ê–Ø"}
        
        report = f"""
================================================================================
                    –ó–ê–ö–õ–Æ–ß–ï–ù–ò–ï –Æ–†–ò–î–ò–ß–ï–°–ö–û–ì–û –î–ï–ü–ê–†–¢–ê–ú–ï–ù–¢–ê
                 –ê–û ¬´–ù–æ–≤–∞—è –ø–µ—Ä–µ–≤–æ–∑–æ—á–Ω–∞—è –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è¬ª
================================================================================

–î–∞—Ç–∞: {datetime.now().strftime('%d.%m.%Y %H:%M')}
–ò—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å: {user.get('name', '')}
–î–æ–ª–∂–Ω–æ—Å—Ç—å: {user.get('position', '')}
–ü–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ: {user.get('department', '')}
ID –∞–Ω–∞–ª–∏–∑–∞: {data.get('analysis_id', '')}

--------------------------------------------------------------------------------
                         1. –û–ë–©–ò–ï –°–í–ï–î–ï–ù–ò–Ø –û –î–û–ì–û–í–û–†–ï
--------------------------------------------------------------------------------

–ö–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç: {data.get('counterparty', '–ù–µ —É–∫–∞–∑–∞–Ω')}
–ù–æ–º–µ—Ä –¥–æ–≥–æ–≤–æ—Ä–∞: {data.get('contract_number', '–ù–µ —É–∫–∞–∑–∞–Ω')}
–î–∞—Ç–∞ –¥–æ–≥–æ–≤–æ—Ä–∞: {data.get('contract_date', '–ù–µ —É–∫–∞–∑–∞–Ω–∞')}
–¢–∏–ø –¥–æ–≥–æ–≤–æ—Ä–∞: {data.get('contract_type', '–ù–µ —É–∫–∞–∑–∞–Ω')}
–°—É–º–º–∞ –¥–æ–≥–æ–≤–æ—Ä–∞: {data.get('amount', 0):,.2f} —Ä—É–±.
–°—Ç–∞—Ç—É—Å —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–∏—è –Æ–î: {data.get('legal_status_label', '–ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω')}

--------------------------------------------------------------------------------
                         2. –†–ï–ó–£–õ–¨–¢–ê–¢–´ –ê–ù–ê–õ–ò–ó–ê
--------------------------------------------------------------------------------

–ó–û–ù–ê –†–ò–°–ö–ê: {zone_names.get(data.get('zone', ''), '–ù–ï –û–ü–†–ï–î–ï–õ–ï–ù–ê')}
–†–ò–°–ö-–°–ö–û–†: {data.get('risk_score', 0):.1f} / 10
–°–û–û–¢–í–ï–¢–°–¢–í–ò–ï –¢–ò–ü–û–í–û–ô –§–û–†–ú–ï: {data.get('compliance_score', 0):.1f}%

–¢—Ä–µ–±—É–µ—Ç—Å—è —É—á–∞—Å—Ç–∏–µ –Æ–î: {'–î–ê' if data.get('requires_legal') else '–ù–ï–¢'}
–°—Ä–æ–∫ —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–∏—è: {data.get('deadline_days', 0)} —Ä–∞–±–æ—á–∏—Ö –¥–Ω–µ–π
–°–æ–≥–ª–∞—Å—É—é—â–∏–π: {data.get('approver', '–ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω')}

--------------------------------------------------------------------------------
                   3. –ê–ù–ê–õ–ò–ó –ü–û –†–ê–ó–î–ï–õ–ê–ú –¢–ò–ü–û–í–û–ô –§–û–†–ú–´
--------------------------------------------------------------------------------

–¢–∏–ø–æ–≤–∞—è —Ñ–æ—Ä–º–∞: {data.get('tf_name', '–ù–µ –≤—ã–±—Ä–∞–Ω–∞')} ({data.get('tf_code', '')})

"""
        for s in data.get('sections_analysis', []):
            status = s.get('comparison', {}).get('status', 'missing')
            status_icon = {"match": "‚úÖ", "partial": "‚ö†Ô∏è", "deviation": "‚ùå", "missing": "‚ùå"}.get(status, "‚ùì")
            score = s.get('comparison', {}).get('combined_score', 0) * 100
            report += f"{status_icon} {s.get('section_name', '')} ‚Äî –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ: {score:.0f}%\n"
            if s.get('risks'):
                for r in s['risks']:
                    lvl = "üî¥" if r.get('risk_level') == 'red' else "üü°"
                    report += f"   {lvl} –†–ò–°–ö: {r.get('issue', '')}\n"
            report += "\n"
        
        if data.get('missing_sections'):
            report += "\n‚ùå –û–¢–°–£–¢–°–¢–í–£–Æ–©–ò–ï –†–ê–ó–î–ï–õ–´:\n"
            for m in data['missing_sections']:
                report += f"   ‚Ä¢ {m}\n"
        
        report += """
--------------------------------------------------------------------------------
                         4. –í–´–Ø–í–õ–ï–ù–ù–´–ï –†–ò–°–ö–ò
--------------------------------------------------------------------------------

"""
        red_risks = [r for r in data.get('risks', []) if r.get('risk_level') == 'red']
        if red_risks:
            report += "üî¥ –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ï –†–ò–°–ö–ò:\n\n"
            for i, r in enumerate(red_risks, 1):
                report += f"   {i}. {r.get('issue', '')}\n"
                if r.get('context'):
                    report += f"      –ö–æ–Ω—Ç–µ–∫—Å—Ç: {r.get('context', '')[:200]}...\n\n"
        else:
            report += "üî¥ –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ï –†–ò–°–ö–ò: –ù–µ –≤—ã—è–≤–ª–µ–Ω—ã\n\n"
        
        yellow_risks = [r for r in data.get('risks', []) if r.get('risk_level') == 'yellow']
        if yellow_risks:
            report += "üü° –¢–†–ï–ë–£–Æ–¢ –í–ù–ò–ú–ê–ù–ò–Ø:\n\n"
            for i, r in enumerate(yellow_risks, 1):
                report += f"   {i}. {r.get('issue', '')}\n\n"
        else:
            report += "üü° –¢–†–ï–ë–£–Æ–¢ –í–ù–ò–ú–ê–ù–ò–Ø: –ù–µ –≤—ã—è–≤–ª–µ–Ω—ã\n\n"
        
        if ai_analysis:
            report += f"""
--------------------------------------------------------------------------------
                     5. –≠–ö–°–ü–ï–†–¢–ù–û–ï –ó–ê–ö–õ–Æ–ß–ï–ù–ò–ï (AI)
--------------------------------------------------------------------------------

{ai_analysis}

"""
        
        if data.get('recommendations'):
            report += """
--------------------------------------------------------------------------------
                         6. –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò
--------------------------------------------------------------------------------

"""
            for i, rec in enumerate(data['recommendations'], 1):
                report += f"   {i}. {rec}\n"
        
        report += f"""
--------------------------------------------------------------------------------
                         7. –ò–¢–û–ì–û–í–û–ï –ó–ê–ö–õ–Æ–ß–ï–ù–ò–ï
--------------------------------------------------------------------------------

{data.get('conclusion', data.get('summary', '–ó–∞–∫–ª—é—á–µ–Ω–∏–µ —Ñ–æ—Ä–º–∏—Ä—É–µ—Ç—Å—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞.'))}

--------------------------------------------------------------------------------

–í–µ—Ä—Å–∏—è —Å–∏—Å—Ç–µ–º—ã: Legal Traffic Light v5.1 Enterprise
–î–∞—Ç–∞ –∏ –≤—Ä–µ–º—è: {datetime.now().strftime('%d.%m.%Y %H:%M:%S')}

================================================================================
"""
        return report
    
    @classmethod
    def generate_docx_report(cls, data: Dict, user: Dict, ai_analysis: str = "") -> bytes:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è DOCX –æ—Ç—á–µ—Ç–∞"""
        try:
            from docx import Document
            from docx.shared import Inches, Pt, RGBColor
            from docx.enum.text import WD_ALIGN_PARAGRAPH
            from docx.enum.style import WD_STYLE_TYPE
            
            doc = Document()
            
            # –ó–∞–≥–æ–ª–æ–≤–æ–∫
            title = doc.add_heading('–ó–ê–ö–õ–Æ–ß–ï–ù–ò–ï –Æ–†–ò–î–ò–ß–ï–°–ö–û–ì–û –î–ï–ü–ê–†–¢–ê–ú–ï–ù–¢–ê', 0)
            title.alignment = WD_ALIGN_PARAGRAPH.CENTER
            
            subtitle = doc.add_paragraph('–ê–û ¬´–ù–æ–≤–∞—è –ø–µ—Ä–µ–≤–æ–∑–æ—á–Ω–∞—è –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è¬ª')
            subtitle.alignment = WD_ALIGN_PARAGRAPH.CENTER
            
            doc.add_paragraph()
            
            # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
            doc.add_paragraph(f"–î–∞—Ç–∞: {datetime.now().strftime('%d.%m.%Y %H:%M')}")
            doc.add_paragraph(f"–ò—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å: {user.get('name', '')}")
            doc.add_paragraph(f"–î–æ–ª–∂–Ω–æ—Å—Ç—å: {user.get('position', '')}")
            doc.add_paragraph(f"–ü–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ: {user.get('department', '')}")
            doc.add_paragraph(f"ID –∞–Ω–∞–ª–∏–∑–∞: {data.get('analysis_id', '')}")
            
            # –†–∞–∑–¥–µ–ª 1
            doc.add_heading('1. –û–ë–©–ò–ï –°–í–ï–î–ï–ù–ò–Ø –û –î–û–ì–û–í–û–†–ï', level=1)
            
            table = doc.add_table(rows=6, cols=2)
            table.style = 'Table Grid'
            
            rows_data = [
                ("–ö–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç", data.get('counterparty', '–ù–µ —É–∫–∞–∑–∞–Ω')),
                ("–ù–æ–º–µ—Ä –¥–æ–≥–æ–≤–æ—Ä–∞", data.get('contract_number', '–ù–µ —É–∫–∞–∑–∞–Ω')),
                ("–î–∞—Ç–∞ –¥–æ–≥–æ–≤–æ—Ä–∞", data.get('contract_date', '–ù–µ —É–∫–∞–∑–∞–Ω–∞')),
                ("–¢–∏–ø –¥–æ–≥–æ–≤–æ—Ä–∞", data.get('contract_type', '–ù–µ —É–∫–∞–∑–∞–Ω')),
                ("–°—É–º–º–∞ –¥–æ–≥–æ–≤–æ—Ä–∞", f"{data.get('amount', 0):,.2f} —Ä—É–±."),
                ("–°—Ç–∞—Ç—É—Å —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–∏—è", data.get('legal_status_label', '–ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω')),
            ]
            
            for i, (label, value) in enumerate(rows_data):
                table.rows[i].cells[0].text = label
                table.rows[i].cells[1].text = str(value)
            
            # –†–∞–∑–¥–µ–ª 2
            doc.add_heading('2. –†–ï–ó–£–õ–¨–¢–ê–¢–´ –ê–ù–ê–õ–ò–ó–ê', level=1)
            
            zone_names = {"green": "üü¢ –ó–ï–õ–ï–ù–ê–Ø", "yellow": "üü° –ñ–ï–õ–¢–ê–Ø", "red": "üî¥ –ö–†–ê–°–ù–ê–Ø"}
            zone = data.get('zone', '')
            
            p = doc.add_paragraph()
            p.add_run(f"–ó–û–ù–ê –†–ò–°–ö–ê: {zone_names.get(zone, '–ù–ï –û–ü–†–ï–î–ï–õ–ï–ù–ê')}").bold = True
            
            doc.add_paragraph(f"–†–∏—Å–∫-—Å–∫–æ—Ä: {data.get('risk_score', 0):.1f} / 10")
            doc.add_paragraph(f"–°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –¢–§: {data.get('compliance_score', 0):.1f}%")
            doc.add_paragraph(f"–¢—Ä–µ–±—É–µ—Ç—Å—è —É—á–∞—Å—Ç–∏–µ –Æ–î: {'–î–ê' if data.get('requires_legal') else '–ù–ï–¢'}")
            doc.add_paragraph(f"–°—Ä–æ–∫ —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–∏—è: {data.get('deadline_days', 0)} —Ä–∞–±–æ—á–∏—Ö –¥–Ω–µ–π")
            
            # –†–∞–∑–¥–µ–ª 3
            doc.add_heading('3. –ê–ù–ê–õ–ò–ó –ü–û –†–ê–ó–î–ï–õ–ê–ú', level=1)
            doc.add_paragraph(f"–¢–∏–ø–æ–≤–∞—è —Ñ–æ—Ä–º–∞: {data.get('tf_name', '')} ({data.get('tf_code', '')})")
            
            for s in data.get('sections_analysis', []):
                status = s.get('comparison', {}).get('status', 'missing')
                status_icon = {"match": "‚úÖ", "partial": "‚ö†Ô∏è", "deviation": "‚ùå", "missing": "‚ùå"}.get(status, "‚ùì")
                score = s.get('comparison', {}).get('combined_score', 0) * 100
                
                p = doc.add_paragraph()
                p.add_run(f"{status_icon} {s.get('section_name', '')}").bold = True
                p.add_run(f" ‚Äî {score:.0f}%")
                
                for r in s.get('risks', []):
                    lvl = "üî¥" if r.get('risk_level') == 'red' else "üü°"
                    doc.add_paragraph(f"   {lvl} {r.get('issue', '')}", style='List Bullet')
            
            # –†–∞–∑–¥–µ–ª 4
            doc.add_heading('4. –í–´–Ø–í–õ–ï–ù–ù–´–ï –†–ò–°–ö–ò', level=1)
            
            red_risks = [r for r in data.get('risks', []) if r.get('risk_level') == 'red']
            if red_risks:
                doc.add_paragraph("–ö–†–ò–¢–ò–ß–ï–°–ö–ò–ï –†–ò–°–ö–ò:", style='Intense Quote')
                for r in red_risks:
                    doc.add_paragraph(f"‚Ä¢ {r.get('issue', '')}")
            
            yellow_risks = [r for r in data.get('risks', []) if r.get('risk_level') == 'yellow']
            if yellow_risks:
                doc.add_paragraph("–¢–†–ï–ë–£–Æ–¢ –í–ù–ò–ú–ê–ù–ò–Ø:", style='Intense Quote')
                for r in yellow_risks:
                    doc.add_paragraph(f"‚Ä¢ {r.get('issue', '')}")
            
            # AI –∞–Ω–∞–ª–∏–∑
            if ai_analysis:
                doc.add_heading('5. –≠–ö–°–ü–ï–†–¢–ù–û–ï –ó–ê–ö–õ–Æ–ß–ï–ù–ò–ï (AI)', level=1)
                doc.add_paragraph(ai_analysis)
            
            # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
            if data.get('recommendations'):
                doc.add_heading('6. –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò', level=1)
                for rec in data['recommendations']:
                    doc.add_paragraph(rec, style='List Number')
            
            # –ó–∞–∫–ª—é—á–µ–Ω–∏–µ
            doc.add_heading('7. –ò–¢–û–ì–û–í–û–ï –ó–ê–ö–õ–Æ–ß–ï–ù–ò–ï', level=1)
            doc.add_paragraph(data.get('conclusion', data.get('summary', '')))
            
            # –§—É—Ç–µ—Ä
            doc.add_paragraph()
            doc.add_paragraph(f"Legal Traffic Light v5.1 | {datetime.now().strftime('%d.%m.%Y %H:%M:%S')}")
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –±–∞–π—Ç—ã
            buffer = io.BytesIO()
            doc.save(buffer)
            buffer.seek(0)
            return buffer.getvalue()
            
        except ImportError:
            return b"Error: Install python-docx"
        except Exception as e:
            return f"Error: {str(e)}".encode()
    
    @classmethod
    def generate_pdf_report(cls, data: Dict, user: Dict, ai_analysis: str = "") -> bytes:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è PDF –æ—Ç—á–µ—Ç–∞"""
        try:
            from fpdf import FPDF
            
            class PDF(FPDF):
                def header(self):
                    self.set_font('DejaVu', 'B', 12)
                    self.cell(0, 10, '–ó–ê–ö–õ–Æ–ß–ï–ù–ò–ï –Æ–†–ò–î–ò–ß–ï–°–ö–û–ì–û –î–ï–ü–ê–†–¢–ê–ú–ï–ù–¢–ê', 0, 1, 'C')
                    self.set_font('DejaVu', '', 10)
                    self.cell(0, 5, '–ê–û ¬´–ù–æ–≤–∞—è –ø–µ—Ä–µ–≤–æ–∑–æ—á–Ω–∞—è –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è¬ª', 0, 1, 'C')
                    self.ln(5)
                
                def footer(self):
                    self.set_y(-15)
                    self.set_font('DejaVu', 'I', 8)
                    self.cell(0, 10, f'Legal Traffic Light v5.1 | –°—Ç—Ä–∞–Ω–∏—Ü–∞ {self.page_no()}', 0, 0, 'C')
            
            pdf = PDF()
            
            # –î–æ–±–∞–≤–ª—è–µ–º —à—Ä–∏—Ñ—Ç —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –∫–∏—Ä–∏–ª–ª–∏—Ü—ã
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π —à—Ä–∏—Ñ—Ç
            pdf.add_font('DejaVu', '', '/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', uni=True)
            pdf.add_font('DejaVu', 'B', '/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', uni=True)
            pdf.add_font('DejaVu', 'I', '/usr/share/fonts/truetype/dejavu/DejaVuSans-Oblique.ttf', uni=True)
            
            pdf.add_page()
            pdf.set_font('DejaVu', '', 10)
            
            # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
            pdf.cell(0, 6, f"–î–∞—Ç–∞: {datetime.now().strftime('%d.%m.%Y %H:%M')}", 0, 1)
            pdf.cell(0, 6, f"–ò—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å: {user.get('name', '')}", 0, 1)
            pdf.cell(0, 6, f"ID –∞–Ω–∞–ª–∏–∑–∞: {data.get('analysis_id', '')}", 0, 1)
            pdf.ln(5)
            
            # –†–∞–∑–¥–µ–ª 1
            pdf.set_font('DejaVu', 'B', 11)
            pdf.cell(0, 8, '1. –û–ë–©–ò–ï –°–í–ï–î–ï–ù–ò–Ø –û –î–û–ì–û–í–û–†–ï', 0, 1)
            pdf.set_font('DejaVu', '', 10)
            
            pdf.cell(0, 6, f"–ö–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç: {data.get('counterparty', '–ù–µ —É–∫–∞–∑–∞–Ω')}", 0, 1)
            pdf.cell(0, 6, f"–°—É–º–º–∞: {data.get('amount', 0):,.2f} —Ä—É–±.", 0, 1)
            pdf.cell(0, 6, f"–¢–∏–ø: {data.get('contract_type', '')}", 0, 1)
            pdf.ln(5)
            
            # –†–∞–∑–¥–µ–ª 2
            pdf.set_font('DejaVu', 'B', 11)
            pdf.cell(0, 8, '2. –†–ï–ó–£–õ–¨–¢–ê–¢–´ –ê–ù–ê–õ–ò–ó–ê', 0, 1)
            pdf.set_font('DejaVu', '', 10)
            
            zone_names = {"green": "–ó–ï–õ–ï–ù–ê–Ø", "yellow": "–ñ–ï–õ–¢–ê–Ø", "red": "–ö–†–ê–°–ù–ê–Ø"}
            pdf.cell(0, 6, f"–ó–æ–Ω–∞ —Ä–∏—Å–∫–∞: {zone_names.get(data.get('zone', ''), '–ù–ï –û–ü–†–ï–î–ï–õ–ï–ù–ê')}", 0, 1)
            pdf.cell(0, 6, f"–†–∏—Å–∫-—Å–∫–æ—Ä: {data.get('risk_score', 0):.1f} / 10", 0, 1)
            pdf.cell(0, 6, f"–°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –¢–§: {data.get('compliance_score', 0):.1f}%", 0, 1)
            pdf.ln(5)
            
            # –†–∞–∑–¥–µ–ª 3 - –†–∏—Å–∫–∏
            pdf.set_font('DejaVu', 'B', 11)
            pdf.cell(0, 8, '3. –í–´–Ø–í–õ–ï–ù–ù–´–ï –†–ò–°–ö–ò', 0, 1)
            pdf.set_font('DejaVu', '', 10)
            
            red_risks = [r for r in data.get('risks', []) if r.get('risk_level') == 'red']
            if red_risks:
                pdf.set_font('DejaVu', 'B', 10)
                pdf.cell(0, 6, '–ö–†–ò–¢–ò–ß–ï–°–ö–ò–ï:', 0, 1)
                pdf.set_font('DejaVu', '', 9)
                for r in red_risks:
                    pdf.multi_cell(0, 5, f"‚Ä¢ {r.get('issue', '')}")
            
            yellow_risks = [r for r in data.get('risks', []) if r.get('risk_level') == 'yellow']
            if yellow_risks:
                pdf.set_font('DejaVu', 'B', 10)
                pdf.cell(0, 6, '–í–ù–ò–ú–ê–ù–ò–ï:', 0, 1)
                pdf.set_font('DejaVu', '', 9)
                for r in yellow_risks:
                    pdf.multi_cell(0, 5, f"‚Ä¢ {r.get('issue', '')}")
            
            if not red_risks and not yellow_risks:
                pdf.cell(0, 6, '–†–∏—Å–∫–∏ –Ω–µ –≤—ã—è–≤–ª–µ–Ω—ã', 0, 1)
            
            pdf.ln(5)
            
            # –ó–∞–∫–ª—é—á–µ–Ω–∏–µ
            pdf.set_font('DejaVu', 'B', 11)
            pdf.cell(0, 8, '4. –ó–ê–ö–õ–Æ–ß–ï–ù–ò–ï', 0, 1)
            pdf.set_font('DejaVu', '', 10)
            pdf.multi_cell(0, 6, data.get('conclusion', data.get('summary', '')))
            
            return pdf.output(dest='S').encode('latin-1')
            
        except ImportError:
            # Fallback - –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç—á–µ—Ç
            return cls.generate_text_report(data, user, ai_analysis).encode('utf-8')
        except Exception as e:
            return f"Error generating PDF: {str(e)}".encode()
    
    @classmethod
    def generate_json_for_1c(cls, data: Dict, user: Dict) -> str:
        """JSON –¥–ª—è 1–°"""
        report = {
            "–î–æ–∫—É–º–µ–Ω—Ç": "–ó–∞–∫–ª—é—á–µ–Ω–∏–µ–Æ–î",
            "–í–µ—Ä—Å–∏—è": "2.0",
            "–î–∞—Ç–∞–°–æ–∑–¥–∞–Ω–∏—è": datetime.now().isoformat(),
            "–û—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è": "–ê–û –ù–ü–ö",
            "–ê–≤—Ç–æ—Ä": {"–§–ò–û": user.get("name", ""), "–î–æ–ª–∂–Ω–æ—Å—Ç—å": user.get("position", ""), "–ü–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ": user.get("department", "")},
            "–ü–∞—Ä–∞–º–µ—Ç—Ä—ã–î–æ–≥–æ–≤–æ—Ä–∞": {
                "–ù–æ–º–µ—Ä": data.get("contract_number", ""),
                "–î–∞—Ç–∞": data.get("contract_date", ""),
                "–ö–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç": data.get("counterparty", ""),
                "–°—É–º–º–∞": data.get("amount", 0),
                "–í–∞–ª—é—Ç–∞": "RUB",
                "–¢–∏–ø–î–æ–≥–æ–≤–æ—Ä–∞": data.get("contract_type", ""),
            },
            "–†–µ–∑—É–ª—å—Ç–∞—Ç–ê–Ω–∞–ª–∏–∑–∞": {
                "–ó–æ–Ω–∞–†–∏—Å–∫–∞": data.get("zone", ""),
                "–†–∏—Å–∫–°–∫–æ—Ä": data.get("risk_score", 0),
                "–°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ–¢–§": data.get("compliance_score", 0),
                "–ö–æ–¥–¢–§": data.get("tf_code", ""),
                "–°—Ç–∞—Ç—É—Å–°–æ–≥–ª–∞—Å–æ–≤–∞–Ω–∏—è–Æ–î": data.get("legal_status", ""),
                "–°—Ä–æ–∫–°–æ–≥–ª–∞—Å–æ–≤–∞–Ω–∏—è": data.get("deadline_days", 0),
                "–°–æ–≥–ª–∞—Å—É—é—â–∏–π": data.get("approver", ""),
                "–¢—Ä–µ–±—É–µ—Ç—Å—è–£—á–∞—Å—Ç–∏–µ–Æ–î": data.get("requires_legal", False)
            },
            "–ê–Ω–∞–ª–∏–∑–†–∞–∑–¥–µ–ª–æ–≤": [
                {
                    "–†–∞–∑–¥–µ–ª": s.get("section_name", ""),
                    "–û–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–π": s.get("required", False),
                    "–°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ–ü—Ä–æ—Ü–µ–Ω—Ç": s.get("comparison", {}).get("combined_score", 0) * 100,
                    "–°—Ç–∞—Ç—É—Å": s.get("comparison", {}).get("status", "missing"),
                    "–†–∏—Å–∫–∏": [{"–£—Ä–æ–≤–µ–Ω—å": r.get("risk_level", ""), "–û–ø–∏—Å–∞–Ω–∏–µ": r.get("issue", "")} for r in s.get("risks", [])]
                }
                for s in data.get("sections_analysis", [])
            ],
            "–í—ã—è–≤–ª–µ–Ω–Ω—ã–µ–†–∏—Å–∫–∏": {
                "–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ": [{"–û–ø–∏—Å–∞–Ω–∏–µ": r.get("issue", ""), "–ö–æ–Ω—Ç–µ–∫—Å—Ç": r.get("context", "")[:500]} for r in data.get("risks", []) if r.get("risk_level") == "red"],
                "–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è": [{"–û–ø–∏—Å–∞–Ω–∏–µ": r.get("issue", ""), "–ö–æ–Ω—Ç–µ–∫—Å—Ç": r.get("context", "")[:500]} for r in data.get("risks", []) if r.get("risk_level") == "yellow"]
            },
            "–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ–†–∞–∑–¥–µ–ª—ã": data.get("missing_sections", []),
            "–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏": data.get("recommendations", []),
            "–ó–∞–∫–ª—é—á–µ–Ω–∏–µ": data.get("conclusion", ""),
            "–°–ª—É–∂–µ–±–Ω–∞—è–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è": {"–ò–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä–ê–Ω–∞–ª–∏–∑–∞": data.get("analysis_id", ""), "–í–µ—Ä—Å–∏—è–°–∏—Å—Ç–µ–º—ã": "5.1"}
        }
        return json.dumps(report, ensure_ascii=False, indent=2)
    
    @classmethod
    def generate_json_knowledge_base(cls, data: Dict, user: Dict, contract_text: str = "") -> str:
        """JSON –¥–ª—è –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π"""
        kb_entry = {
            "id": data.get("analysis_id", ""),
            "timestamp": datetime.now().isoformat(),
            "type": "contract_analysis",
            "metadata": {
                "counterparty": data.get("counterparty", ""),
                "contract_number": data.get("contract_number", ""),
                "contract_date": data.get("contract_date", ""),
                "contract_type": data.get("contract_type", ""),
                "amount": data.get("amount", 0),
                "analyst": user.get("name", ""),
                "department": user.get("department", ""),
            },
            "analysis": {
                "risk_zone": data.get("zone", ""),
                "risk_score": data.get("risk_score", 0),
                "compliance_score": data.get("compliance_score", 0),
                "typical_form": {"name": data.get("tf_name", ""), "code": data.get("tf_code", "")},
                "legal_status": data.get("legal_status", ""),
                "requires_legal_review": data.get("requires_legal", False),
            },
            "risks": {
                "critical": [{"issue": r.get("issue", ""), "context": r.get("context", "")[:300]} for r in data.get("risks", []) if r.get("risk_level") == "red"],
                "warnings": [{"issue": r.get("issue", ""), "context": r.get("context", "")[:300]} for r in data.get("risks", []) if r.get("risk_level") == "yellow"]
            },
            "sections": {
                "missing": data.get("missing_sections", []),
                "deviations": data.get("deviation_sections", []),
                "analysis": [
                    {"name": s.get("section_name", ""), "score": s.get("comparison", {}).get("combined_score", 0), "status": s.get("comparison", {}).get("status", ""), "risks": len(s.get("risks", []))}
                    for s in data.get("sections_analysis", [])
                ]
            },
            "recommendations": data.get("recommendations", []),
            "conclusion": data.get("conclusion", ""),
            "contract_text_hash": hashlib.md5(contract_text.encode()).hexdigest() if contract_text else "",
            "version": "5.1"
        }
        return json.dumps(kb_entry, ensure_ascii=False, indent=2)

# ============================================================================
# –ë–ï–ó–û–ü–ê–°–ù–û–°–¢–¨
# ============================================================================

class SecurityValidator:
    ALLOWED_EXTENSIONS = {'.txt', '.docx', '.pdf', '.doc', '.json'}
    MAX_FILE_SIZE = 15 * 1024 * 1024
    MAX_TEXT_LENGTH = 1_000_000
    
    DANGEROUS_PATTERNS = [r'<script[^>]*>.*?</script>', r'javascript:', r'on\w+\s*=', r'<iframe[^>]*>', r'eval\s*\(']
    
    @classmethod
    def sanitize_text(cls, text: str) -> str:
        if not text:
            return ""
        text = html.escape(text)
        for pattern in cls.DANGEROUS_PATTERNS:
            text = re.sub(pattern, '', text, flags=re.IGNORECASE | re.DOTALL)
        return text[:cls.MAX_TEXT_LENGTH]
    
    @classmethod
    def validate_file(cls, f) -> Tuple[bool, str]:
        if not f:
            return False, "–§–∞–π–ª –Ω–µ –≤—ã–±—Ä–∞–Ω"
        if f.size > cls.MAX_FILE_SIZE:
            return False, f"–§–∞–π–ª > {cls.MAX_FILE_SIZE // 1024 // 1024} MB"
        ext = '.' + f.name.split('.')[-1].lower()
        if ext not in cls.ALLOWED_EXTENSIONS:
            return False, f"–†–∞–∑—Ä–µ—à–µ–Ω—ã: {', '.join(cls.ALLOWED_EXTENSIONS)}"
        return True, "OK"
    
    @classmethod
    def validate_user(cls, name: str, position: str, department: str) -> Tuple[bool, str]:
        if not name or len(name.strip()) < 5:
            return False, "–§–ò–û: –º–∏–Ω–∏–º—É–º 5 —Å–∏–º–≤–æ–ª–æ–≤"
        if not position:
            return False, "–í—ã–±–µ—Ä–∏—Ç–µ –¥–æ–ª–∂–Ω–æ—Å—Ç—å"
        if not department:
            return False, "–í—ã–±–µ—Ä–∏—Ç–µ –ø–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ"
        return True, "OK"
    
    @classmethod
    def validate_amount(cls, value: str) -> Tuple[bool, float, str]:
        try:
            cleaned = re.sub(r'[^\d.,]', '', value).replace(',', '.')
            if not cleaned:
                return True, 0, "OK"
            amount = float(cleaned)
            return True, amount, "OK"
        except:
            return False, 0, "–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç"

# ============================================================================
# –û–ü–†–ï–î–ï–õ–ï–ù–ò–ï –ó–û–ù–´ –†–ò–°–ö–ê
# ============================================================================

@dataclass
class AnalysisInput:
    amount: float = 0
    document_form: DocumentForm = DocumentForm.TYPICAL
    document_type: str = ""
    deal_type: str = ""
    legal_status: LegalStatus = LegalStatus.NOT_SUBMITTED
    is_single_supplier: bool = False
    is_tender: bool = False
    tender_amount: float = 0
    contract_years: int = 0
    changes_essential: bool = False
    is_urgent: bool = False
    counterparty: str = ""
    contract_number: str = ""
    contract_date: str = ""

@dataclass
class ZoneResult:
    zone: RiskZone = RiskZone.GREEN
    zone_reason: str = ""
    deadline_days: int = 0
    requires_legal: bool = False
    responsible: str = "–ò–Ω–∏—Ü–∏–∞—Ç–æ—Ä"
    recommendations: List[str] = field(default_factory=list)
    warnings: List[str] = field(default_factory=list)
    red_flags: List[str] = field(default_factory=list)
    yellow_flags: List[str] = field(default_factory=list)
    green_flags: List[str] = field(default_factory=list)
    required_documents: List[str] = field(default_factory=list)
    approval_route: List[str] = field(default_factory=list)

def determine_risk_zone(inp: AnalysisInput) -> ZoneResult:
    result = ZoneResult()
    
    # –ö–†–ê–°–ù–ê–Ø –ø–æ —Ç–∏–ø—É —Å–¥–µ–ª–∫–∏
    if inp.deal_type and inp.deal_type in RED_ZONE_ALWAYS:
        result.zone = RiskZone.RED
        result.zone_reason = f"'{inp.deal_type}' ‚Äî –≤—Å–µ–≥–¥–∞ –∫—Ä–∞—Å–Ω–∞—è –∑–æ–Ω–∞ (–ø. 4.3)"
        result.red_flags.append(f"–°—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫–∞—è —Å–¥–µ–ª–∫–∞: {inp.deal_type}")
        result.requires_legal = True
        result.responsible = "–Æ—Ä–∏–¥–∏—á–µ—Å–∫–∏–π –¥–µ–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç"
        result.deadline_days = Deadlines.EXTENDED
        result.approval_route = ["–Æ–î (—ç—Ç–∞–ø –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è)", "–°–æ–≤–º–µ—Å—Ç–Ω–∞—è —Ä–∞–±–æ—Ç–∞"]
        result.required_documents = ["–û–ø–∏—Å–∞–Ω–∏–µ –∑–∞–¥–∞—á–∏", "–ü—Ä–æ–µ–∫—Ç –¥–æ–≥–æ–≤–æ—Ä–∞", "–¢–ó", "–ö–ü", "–ö–∞—Ä—Ç–æ—á–∫–∞ –∫–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç–∞"]
        return result
    
    if inp.document_type and inp.document_type in RED_DOCUMENTS_ALWAYS:
        result.zone = RiskZone.RED
        result.zone_reason = f"'{inp.document_type}' ‚Äî –≤—Å–µ–≥–¥–∞ –∫—Ä–∞—Å–Ω–∞—è –∑–æ–Ω–∞"
        result.red_flags.append(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π –¥–æ–∫—É–º–µ–Ω—Ç: {inp.document_type}")
        result.requires_legal = True
        result.responsible = "–Æ—Ä–∏–¥–∏—á–µ—Å–∫–∏–π –¥–µ–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç"
        result.deadline_days = Deadlines.URGENT
        result.approval_route = ["–Æ–î –ù–ï–ó–ê–ú–ï–î–õ–ò–¢–ï–õ–¨–ù–û"]
        result.warnings.append("‚ö†Ô∏è –ù–ï–ú–ï–î–õ–ï–ù–ù–û–ï –ø—Ä–∏–≤–ª–µ—á–µ–Ω–∏–µ –Æ–î!")
        return result
    
    if inp.is_tender and inp.tender_amount > Thresholds.TENDER_RED:
        result.zone = RiskZone.RED
        result.zone_reason = f"–¢–µ–Ω–¥–µ—Ä > 3 000 000 —Ä—É–±."
        result.red_flags.append(f"–¢–µ–Ω–¥–µ—Ä {inp.tender_amount:,.0f} —Ä—É–±.")
        result.requires_legal = True
        result.responsible = "–Æ—Ä–∏–¥–∏—á–µ—Å–∫–∏–π –¥–µ–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç"
        result.deadline_days = Deadlines.EXTENDED
        return result
    
    if inp.amount > Thresholds.YELLOW_MAX:
        result.zone = RiskZone.RED
        result.zone_reason = f"–°—É–º–º–∞ {inp.amount:,.0f} —Ä—É–±. > 5 000 000"
        result.red_flags.append("–°—É–º–º–∞ > 5 –º–ª–Ω —Ä—É–±.")
        result.requires_legal = True
        result.responsible = "–Æ—Ä–∏–¥–∏—á–µ—Å–∫–∏–π –¥–µ–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç"
        result.deadline_days = Deadlines.EXTENDED
        result.approval_route = ["–Æ–î (–ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ)", "–°–æ–≤–º–µ—Å—Ç–Ω–∞—è —Ä–∞–±–æ—Ç–∞"]
        return result
    
    # –ñ–ï–õ–¢–ê–Ø –∑–æ–Ω–∞
    yellow_reasons = []
    
    if inp.deal_type and inp.deal_type in YELLOW_ZONE_TYPES:
        yellow_reasons.append(inp.deal_type)
        result.yellow_flags.append(inp.deal_type)
    
    if inp.is_single_supplier and inp.amount > Thresholds.SINGLE_SUPPLIER_YELLOW:
        yellow_reasons.append("–ï–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω—ã–π –ø–æ—Å—Ç–∞–≤—â–∏–∫ > 100–ö")
        result.yellow_flags.append("–ï–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω—ã–π –ø–æ—Å—Ç–∞–≤—â–∏–∫")
    
    if inp.contract_years > Thresholds.CONTRACT_CONTROL_YEARS:
        yellow_reasons.append(f"–ö–æ–Ω—Ç—Ä–æ–ª—å–Ω—ã–π —Å—Ä–æ–∫ > {Thresholds.CONTRACT_CONTROL_YEARS} –ª–µ—Ç")
        result.yellow_flags.append(f"–î–æ–≥–æ–≤–æ—Ä > {inp.contract_years} –ª–µ—Ç")
    
    if inp.document_form == DocumentForm.TYPICAL:
        if inp.amount > Thresholds.GREEN_TF_MAX:
            yellow_reasons.append(f"–¢–§ > 100–ö")
            result.yellow_flags.append(f"–¢–§: {inp.amount:,.0f} —Ä—É–±.")
        else:
            result.green_flags.append("–¢–§ ‚â§ 100–ö")
    elif inp.document_form in [DocumentForm.COUNTERPARTY, DocumentForm.FREE, DocumentForm.SELF_DEVELOPED]:
        if inp.amount > Thresholds.GREEN_NON_TF_MAX:
            yellow_reasons.append("–ù–µ—Ç–∏–ø–æ–≤–∞—è —Ñ–æ—Ä–º–∞ > 50–ö")
            result.yellow_flags.append("–ù–µ—Ç–∏–ø–æ–≤–∞—è > 50–ö")
        else:
            result.green_flags.append("–ù–µ—Ç–∏–ø–æ–≤–∞—è ‚â§ 50–ö")
    elif inp.document_form == DocumentForm.MODIFIED_TF:
        if inp.changes_essential:
            yellow_reasons.append("–ò–∑–º–µ–Ω–µ–Ω–∏–µ —Å—É—â–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö —É—Å–ª–æ–≤–∏–π")
            result.yellow_flags.append("–°—É—â–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è –¢–§")
        elif inp.amount > Thresholds.GREEN_NON_TF_MAX:
            yellow_reasons.append("–ò–∑–º–µ–Ω–µ–Ω–∏—è –¢–§ > 50–ö")
            result.yellow_flags.append("–ò–∑–º–µ–Ω–µ–Ω–∏—è –¢–§ > 50–ö")
        else:
            result.green_flags.append("–ò–∑–º–µ–Ω–µ–Ω–∏—è –¢–§ ‚â§ 50–ö")
    
    if yellow_reasons:
        result.zone = RiskZone.YELLOW
        result.zone_reason = "; ".join(yellow_reasons)
        result.requires_legal = True
        result.responsible = "–Æ–î (—ç–∫—Å–ø–µ—Ä—Ç–∏–∑–∞)"
        result.deadline_days = Deadlines.STANDARD
        result.approval_route = ["–ò–Ω–∏—Ü–∏–∞—Ç–æ—Ä ‚Üí –°–≠–î ‚Üí –Æ–î (5 –¥–Ω.) ‚Üí –ü–æ–¥–ø–∏—Å–∞–Ω–∏–µ"]
        result.required_documents = ["–ü—Ä–æ–µ–∫—Ç –¥–æ–≥–æ–≤–æ—Ä–∞", "–¢–ó", "–ö–ü", "–ö–∞—Ä—Ç–æ—á–∫–∞ –∫–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç–∞"]
        result.warnings.append("‚ö†Ô∏è –ó–ê–ü–†–ï–©–ï–ù–û –ø–æ–¥–ø–∏—Å–∞–Ω–∏–µ –¥–æ –≤–∏–∑—ã –Æ–î!")
        return result
    
    # –ó–ï–õ–ï–ù–ê–Ø
    result.zone = RiskZone.GREEN
    result.zone_reason = "–ó–µ–ª–µ–Ω—ã–π –∫–æ—Ä–∏–¥–æ—Ä (–ø. 4.1)"
    result.requires_legal = False
    result.responsible = "–ò–Ω–∏—Ü–∏–∞—Ç–æ—Ä"
    result.approval_route = ["–ò–Ω–∏—Ü–∏–∞—Ç–æ—Ä ‚Üí –†—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å ‚Üí –ü–æ–¥–ø–∏—Å–∞–Ω–∏–µ"]
    result.recommendations.append("–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∞–∫—Ç—É–∞–ª—å–Ω—É—é –¢–§ –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π")
    
    return result

# ============================================================================
# –ò–°–¢–û–†–ò–Ø
# ============================================================================

def add_to_history(data: Dict):
    if "history" not in st.session_state:
        st.session_state.history = []
    data["id"] = hashlib.md5(f"{datetime.now().isoformat()}{data.get('counterparty', '')}".encode()).hexdigest()[:8]
    data["timestamp"] = datetime.now().isoformat()
    st.session_state.history.insert(0, data)
    if len(st.session_state.history) > 100:
        st.session_state.history = st.session_state.history[:100]

# ============================================================================
# –°–¢–ò–õ–ò
# ============================================================================

def apply_styles():
    st.markdown("""
    <style>
        :root { --red: #dc3545; --yellow: #ffc107; --green: #28a745; --blue: #0d6efd; --purple: #6f42c1; }
        .main-header { background: linear-gradient(135deg, #1a1a2e 0%, #16213e 50%, #0f3460 100%); padding: 1.5rem 2rem; border-radius: 12px; margin-bottom: 1.5rem; color: white; }
        .traffic-light { display: flex; gap: 8px; margin-bottom: 0.5rem; }
        .traffic-light span { width: 18px; height: 18px; border-radius: 50%; }
        .tl-red { background: var(--red); box-shadow: 0 0 10px var(--red); }
        .tl-yellow { background: var(--yellow); box-shadow: 0 0 10px var(--yellow); }
        .tl-green { background: var(--green); box-shadow: 0 0 10px var(--green); }
        .version-badge { background: var(--purple); padding: 2px 10px; border-radius: 10px; font-size: 0.7rem; margin-left: 10px; }
        .zone-card { border-radius: 12px; padding: 1.5rem; margin-bottom: 1rem; border-left: 5px solid; }
        .zone-card.green { background: linear-gradient(135deg, #d4edda 0%, #c3e6cb 100%); border-left-color: var(--green); }
        .zone-card.yellow { background: linear-gradient(135deg, #fff3cd 0%, #ffeeba 100%); border-left-color: var(--yellow); }
        .zone-card.red { background: linear-gradient(135deg, #f8d7da 0%, #f5c6cb 100%); border-left-color: var(--red); }
        .zone-title { font-size: 1.2rem; font-weight: bold; margin-bottom: 0.5rem; }
        .risk-item { background: #f8f9fa; border-radius: 8px; padding: 1rem; margin-bottom: 0.8rem; border-left: 3px solid; }
        .risk-item.red { border-left-color: var(--red); background: #fff5f5; }
        .risk-item.yellow { border-left-color: var(--yellow); background: #fffcf0; }
        .risk-item.green { border-left-color: var(--green); background: #f0fff4; }
        .section-score { display: inline-block; padding: 2px 8px; border-radius: 4px; font-size: 0.8rem; font-weight: bold; }
        .score-high { background: #d4edda; color: #155724; }
        .score-medium { background: #fff3cd; color: #856404; }
        .score-low { background: #f8d7da; color: #721c24; }
        footer { visibility: hidden; }
    </style>
    """, unsafe_allow_html=True)

# ============================================================================
# SESSION STATE
# ============================================================================

def init_session():
    defaults = {
        "authenticated": False, "user": None, "demo_mode": False,
        "contract_text": "", "zone_result": None, "comparison_result": None,
        "ai_analysis": "", "history": [], "current_input": None,
        "custom_typical_forms": {}, "selected_tf": None
    }
    for k, v in defaults.items():
        if k not in st.session_state:
            st.session_state[k] = v

# ============================================================================
# –î–ï–ú–û
# ============================================================================

DEMO_CONTRACT = """–î–û–ì–û–í–û–† –û–ö–ê–ó–ê–ù–ò–Ø –£–°–õ–£–ì ‚Ññ 2025/IT-001

–≥. –ú–æ—Å–∫–≤–∞                                                     ¬´10¬ª —è–Ω–≤–∞—Ä—è 2025 –≥.

–û–û–û ¬´–ò–¢-–†–µ—à–µ–Ω–∏—è¬ª –∏ –ê–û ¬´–ù–æ–≤–∞—è –ø–µ—Ä–µ–≤–æ–∑–æ—á–Ω–∞—è –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è¬ª –∑–∞–∫–ª—é—á–∏–ª–∏ –¥–æ–≥–æ–≤–æ—Ä:

1. –ü–†–ï–î–ú–ï–¢ –î–û–ì–û–í–û–†–ê
1.1. –ò—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å –æ–±—è–∑—É–µ—Ç—Å—è –æ–∫–∞–∑–∞—Ç—å —É—Å–ª—É–≥–∏ –ø–æ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–π –ø–æ–¥–¥–µ—Ä–∂–∫–µ –ò–°.

2. –°–¢–û–ò–ú–û–°–¢–¨ –ò –ü–û–†–Ø–î–û–ö –†–ê–°–ß–ï–¢–û–í
2.1. –°—Ç–æ–∏–º–æ—Å—Ç—å: 6 000 000 —Ä—É–±–ª–µ–π.
2.2. –û–ø–ª–∞—Ç–∞ –≤ —Ç–µ—á–µ–Ω–∏–µ 5 –¥–Ω–µ–π –ø–æ—Å–ª–µ –ø–æ–¥–ø–∏—Å–∞–Ω–∏—è –ê–∫—Ç–∞.
2.3. –ù–µ—É—Å—Ç–æ–π–∫–∞ –∑–∞ –ø—Ä–æ—Å—Ä–æ—á–∫—É –æ–ø–ª–∞—Ç—ã: 0,5% –≤ –¥–µ–Ω—å.

3. –°–†–û–ö–ò –û–ö–ê–ó–ê–ù–ò–Ø –£–°–õ–£–ì
3.1. –° 01.01.2025 –ø–æ 31.12.2025.

4. –ü–û–†–Ø–î–û–ö –°–î–ê–ß–ò-–ü–†–ò–ï–ú–ö–ò
4.1. –ê–∫—Ç –ø–æ–¥–ø–∏—Å—ã–≤–∞–µ—Ç—Å—è –≤ —Ç–µ—á–µ–Ω–∏–µ 2 —Ä–∞–±–æ—á–∏—Ö –¥–Ω–µ–π.

5. –ü–†–ê–í–ê –ò –û–ë–Ø–ó–ê–ù–ù–û–°–¢–ò
5.1. –ò—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å –æ–∫–∞–∑—ã–≤–∞–µ—Ç —É—Å–ª—É–≥–∏. –ó–∞–∫–∞–∑—á–∏–∫ –æ–ø–ª–∞—á–∏–≤–∞–µ—Ç.

6. –û–¢–í–ï–¢–°–¢–í–ï–ù–ù–û–°–¢–¨ –°–¢–û–†–û–ù
6.1. –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å –ò—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—è –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∞ —Å—É–º–º–æ–π –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –º–µ—Å—è—á–Ω–æ–≥–æ –ø–ª–∞—Ç–µ–∂–∞.
6.2. –ò—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å –Ω–µ –Ω–µ—Å–µ—Ç –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏ –∑–∞ –∫–æ—Å–≤–µ–Ω–Ω—ã–µ —É–±—ã—Ç–∫–∏ –∏ —É–ø—É—â–µ–Ω–Ω—É—é –≤—ã–≥–æ–¥—É.

7. –ö–û–ù–§–ò–î–ï–ù–¶–ò–ê–õ–¨–ù–û–°–¢–¨
7.1. –°—Ä–æ–∫: 5 –ª–µ—Ç –ø–æ—Å–ª–µ –ø—Ä–µ–∫—Ä–∞—â–µ–Ω–∏—è.
7.2. –®—Ç—Ä–∞—Ñ –∑–∞ –Ω–∞—Ä—É—à–µ–Ω–∏–µ: 10 000 000 —Ä—É–±–ª–µ–π.

8. –ò–ù–¢–ï–õ–õ–ï–ö–¢–£–ê–õ–¨–ù–ê–Ø –°–û–ë–°–¢–í–ï–ù–ù–û–°–¢–¨
8.1. –í—Å–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ä–∞–±–æ—Ç —è–≤–ª—è—é—Ç—Å—è –∏—Å–∫–ª—é—á–∏—Ç–µ–ª—å–Ω–æ–π —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å—é –ò—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—è.
8.2. –ó–∞–∫–∞–∑—á–∏–∫—É –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç—Å—è –Ω–µ–∏—Å–∫–ª—é—á–∏—Ç–µ–ª—å–Ω–∞—è –ª–∏—Ü–µ–Ω–∑–∏—è.

9. –°–†–û–ö –î–ï–ô–°–¢–í–ò–Ø –ò –†–ê–°–¢–û–†–ñ–ï–ù–ò–ï
9.1. –î–æ 31.12.2025.
9.2. –ò—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å –≤–ø—Ä–∞–≤–µ —Ä–∞—Å—Ç–æ—Ä–≥–Ω—É—Ç—å –¥–æ–≥–æ–≤–æ—Ä –≤ –æ–¥–Ω–æ—Å—Ç–æ—Ä–æ–Ω–Ω–µ–º –ø–æ—Ä—è–¥–∫–µ –∑–∞ 5 –¥–Ω–µ–π.
9.3. –ó–∞–∫–∞–∑—á–∏–∫ –≤–ø—Ä–∞–≤–µ —Ä–∞—Å—Ç–æ—Ä–≥–Ω—É—Ç—å —Ç–æ–ª—å–∫–æ –ø—Ä–∏ —Å—É—â–µ—Å—Ç–≤–µ–Ω–Ω–æ–º –Ω–∞—Ä—É—à–µ–Ω–∏–∏.

10. –†–ê–ó–†–ï–®–ï–ù–ò–ï –°–ü–û–†–û–í
10.1. –ê—Ä–±–∏—Ç—Ä–∞–∂–Ω—ã–π —Å—É–¥ –≥. –°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥–∞.

11. –§–û–†–°-–ú–ê–ñ–û–†
11.1. –ù–µ–ø—Ä–µ–æ–¥–æ–ª–∏–º–∞—è —Å–∏–ª–∞ –æ—Å–≤–æ–±–æ–∂–¥–∞–µ—Ç –æ—Ç –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏.

12. –ó–ê–ö–õ–Æ–ß–ò–¢–ï–õ–¨–ù–´–ï –ü–û–õ–û–ñ–ï–ù–ò–Ø
12.1. –°—É–±–ø–æ–¥—Ä—è–¥ –±–µ–∑ —Å–æ–≥–ª–∞—Å–∏—è –ó–∞–∫–∞–∑—á–∏–∫–∞.
12.2. –ò—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å –º–æ–∂–µ—Ç –∏–∑–º–µ–Ω–∏—Ç—å —Ü–µ–Ω—É –≤ –æ–¥–Ω–æ—Å—Ç–æ—Ä–æ–Ω–Ω–µ–º –ø–æ—Ä—è–¥–∫–µ –∑–∞ 10 –¥–Ω–µ–π.

13. –†–ï–ö–í–ò–ó–ò–¢–´ –ò –ü–û–î–ü–ò–°–ò –°–¢–û–†–û–ù
–ó–ê–ö–ê–ó–ß–ò–ö: –ê–û ¬´–ù–ü–ö¬ª...
–ò–°–ü–û–õ–ù–ò–¢–ï–õ–¨: –û–û–û ¬´–ò–¢-–†–µ—à–µ–Ω–∏—è¬ª..."""

DEMO_USER = {"name": "–î–µ–º–æ-–ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å", "position": "–°–ø–µ—Ü–∏–∞–ª–∏—Å—Ç", "department": "–Æ—Ä–∏–¥–∏—á–µ—Å–∫–∏–π –¥–µ–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç"}

# ============================================================================
# UI –ö–û–ú–ü–û–ù–ï–ù–¢–´
# ============================================================================

def render_auth():
    st.markdown("""
    <div style="text-align: center; padding: 2rem;">
        <div class="traffic-light" style="justify-content: center;">
            <span class="tl-red"></span><span class="tl-yellow"></span><span class="tl-green"></span>
        </div>
        <h1>üö¶ Legal Traffic Light</h1>
        <p style="color: #6c757d;">–ê–û ¬´–ù–æ–≤–∞—è –ø–µ—Ä–µ–≤–æ–∑–æ—á–Ω–∞—è –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è¬ª</p>
    </div>
    """, unsafe_allow_html=True)
    
    col1, col2, col3 = st.columns([1, 2, 1])
    with col2:
        st.markdown("### üîê –í—Ö–æ–¥")
        with st.form("auth"):
            name = st.text_input("–§–ò–û *", placeholder="–ò–≤–∞–Ω–æ–≤ –ò–≤–∞–Ω –ò–≤–∞–Ω–æ–≤–∏—á")
            position = st.selectbox("–î–æ–ª–∂–Ω–æ—Å—Ç—å *", [""] + POSITIONS)
            department = st.selectbox("–ü–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ *", [""] + DEPARTMENTS)
            col_a, col_b = st.columns(2)
            with col_a:
                if st.form_submit_button("üöÄ –í–æ–π—Ç–∏", use_container_width=True, type="primary"):
                    valid, msg = SecurityValidator.validate_user(name, position, department)
                    if valid:
                        st.session_state.authenticated = True
                        st.session_state.user = {"name": name, "position": position, "department": department}
                        st.rerun()
                    else:
                        st.error(msg)
            with col_b:
                if st.form_submit_button("üìã –î–µ–º–æ", use_container_width=True):
                    st.session_state.authenticated = True
                    st.session_state.user = DEMO_USER.copy()
                    st.session_state.demo_mode = True
                    st.rerun()

def render_sidebar():
    with st.sidebar:
        st.markdown("### üë§ –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å")
        if st.session_state.demo_mode:
            st.info("üéØ –î–µ–º–æ-—Ä–µ–∂–∏–º")
        u = st.session_state.user
        st.markdown(f"**{u['name']}**\n\n{u['position']}\n\n_{u['department']}_")
        if st.button("üö™ –í—ã–π—Ç–∏", use_container_width=True):
            for k in list(st.session_state.keys()):
                del st.session_state[k]
            st.rerun()
        
        st.markdown("---")
        st.markdown("### üìã –ú–∞—Ç—Ä–∏—Ü–∞")
        st.markdown("üü¢ –¢–§ ‚â§100–ö / –ù–µ—Ç–∏–ø. ‚â§50–ö\nüü° ‚â§5–ú / –û—Å–æ–±—ã–µ\nüî¥ >5–ú / –°—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫–∏–µ")
        
        if st.session_state.history:
            st.markdown("---")
            st.markdown("### üìú –ò—Å—Ç–æ—Ä–∏—è")
            for h in st.session_state.history[:5]:
                z = {"green": "üü¢", "yellow": "üü°", "red": "üî¥"}.get(h.get("zone"), "‚ö™")
                st.markdown(f"{z} {h.get('counterparty', 'N/A')[:15]} | {h.get('timestamp', '')[:10]}")

def render_analysis_tab():
    st.markdown("### üìù –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–æ–≥–æ–≤–æ—Ä–∞")
    
    col1, col2 = st.columns(2)
    with col1:
        counterparty = st.text_input("–ö–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç", placeholder="–û–û–û ¬´–ù–∞–∑–≤–∞–Ω–∏–µ¬ª")
        contract_number = st.text_input("–ù–æ–º–µ—Ä –¥–æ–≥–æ–≤–æ—Ä–∞", placeholder="2025/001")
        contract_date = st.date_input("–î–∞—Ç–∞", value=date.today())
        doc_type = st.selectbox("–¢–∏–ø –¥–æ–≥–æ–≤–æ—Ä–∞", ["–î–æ–≥–æ–≤–æ—Ä –æ–∫–∞–∑–∞–Ω–∏—è —É—Å–ª—É–≥", "–î–æ–≥–æ–≤–æ—Ä –ø–æ—Å—Ç–∞–≤–∫–∏", "–î–æ–≥–æ–≤–æ—Ä –∞—Ä–µ–Ω–¥—ã", "–î–æ–≥–æ–≤–æ—Ä –∞—Ä–µ–Ω–¥—ã –≤–∞–≥–æ–Ω–æ–≤", "IT-—É—Å–ª—É–≥–∏", "–î—Ä—É–≥–æ–π"])
        doc_form = st.selectbox("–§–æ—Ä–º–∞", [
            ("–¢–§ –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π", DocumentForm.TYPICAL),
            ("–§–æ—Ä–º–∞ –∫–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç–∞", DocumentForm.COUNTERPARTY),
            ("–°–≤–æ–±–æ–¥–Ω–∞—è —Ñ–æ—Ä–º–∞", DocumentForm.FREE),
            ("–¢–§ —Å –∏–∑–º–µ–Ω–µ–Ω–∏—è–º–∏", DocumentForm.MODIFIED_TF),
            ("–°–∞–º–æ—Å—Ç–æ—è—Ç–µ–ª—å–Ω–∞—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞", DocumentForm.SELF_DEVELOPED),
        ], format_func=lambda x: x[0])[1]
    
    with col2:
        amount_str = st.text_input("–°—É–º–º–∞ (‚ÇΩ)", placeholder="1500000")
        valid_amount, amount, _ = SecurityValidator.validate_amount(amount_str) if amount_str else (True, 0, "")
        
        legal_status = st.selectbox("–°—Ç–∞—Ç—É—Å —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–∏—è –Æ–î", list(LegalStatus), format_func=lambda x: LEGAL_STATUS_LABELS[x])
        deal_type = st.selectbox("–°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π —Ç–∏–ø", ["–ù–µ –ø—Ä–∏–º–µ–Ω–∏–º–æ"] + RED_ZONE_ALWAYS + YELLOW_ZONE_TYPES)
        if deal_type == "–ù–µ –ø—Ä–∏–º–µ–Ω–∏–º–æ":
            deal_type = ""
        
        is_single_supplier = st.checkbox("–ï–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω—ã–π –ø–æ—Å—Ç–∞–≤—â–∏–∫")
        is_tender = st.checkbox("–¢–µ–Ω–¥–µ—Ä")
        tender_amount = 0
        if is_tender:
            t_str = st.text_input("–°—É–º–º–∞ —Ç–µ–Ω–¥–µ—Ä–∞", "")
            if t_str:
                _, tender_amount, _ = SecurityValidator.validate_amount(t_str)
    
    with st.expander("üîß –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ"):
        col_a, col_b = st.columns(2)
        with col_a:
            contract_years = st.number_input("–°—Ä–æ–∫ (–ª–µ—Ç)", 0, 50, 0)
            changes_essential = st.checkbox("–°—É—â–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è")
        with col_b:
            is_urgent = st.checkbox("üö® –°—Ä–æ—á–Ω–æ")
            if is_urgent:
                st.warning("–¢—Ä–µ–±—É–µ—Ç—Å—è –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ!")
    
    st.markdown("---")
    
    col_b1, col_b2, col_b3 = st.columns(3)
    with col_b1:
        if st.button("üö¶ –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∑–æ–Ω—É", type="primary", use_container_width=True):
            inp = AnalysisInput(
                amount=amount, document_form=doc_form, document_type=doc_type, deal_type=deal_type,
                legal_status=legal_status, is_single_supplier=is_single_supplier, is_tender=is_tender,
                tender_amount=tender_amount, contract_years=contract_years, changes_essential=changes_essential,
                is_urgent=is_urgent, counterparty=counterparty, contract_number=contract_number, contract_date=str(contract_date)
            )
            st.session_state.zone_result = determine_risk_zone(inp)
            st.session_state.current_input = inp
            st.rerun()
    with col_b2:
        if st.button("üìù –î–µ–º–æ-–¥–æ–≥–æ–≤–æ—Ä", use_container_width=True):
            st.session_state.contract_text = DEMO_CONTRACT
            st.rerun()
    with col_b3:
        if st.button("üóëÔ∏è –û—á–∏—Å—Ç–∏—Ç—å", use_container_width=True):
            st.session_state.zone_result = None
            st.session_state.comparison_result = None
            st.session_state.ai_analysis = ""
            st.session_state.contract_text = ""
            st.rerun()
    
    # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –∑–æ–Ω—ã
    if st.session_state.zone_result:
        zr = st.session_state.zone_result
        zone_cfg = {
            RiskZone.GREEN: ("green", "üü¢ –ó–ï–õ–ï–ù–ê–Ø", "–°–∞–º–æ—Å—Ç–æ—è—Ç–µ–ª—å–Ω–æ"),
            RiskZone.YELLOW: ("yellow", "üü° –ñ–ï–õ–¢–ê–Ø", "–°–æ–≥–ª–∞—Å–æ–≤–∞–Ω–∏–µ –Æ–î"),
            RiskZone.RED: ("red", "üî¥ –ö–†–ê–°–ù–ê–Ø", "–ü–æ–ª–Ω–æ–µ —Å–æ–ø—Ä–æ–≤–æ–∂–¥–µ–Ω–∏–µ"),
        }
        
        # –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –ø–æ–ª—É—á–µ–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –∑–æ–Ω—ã
        if zr.zone in zone_cfg:
            zc, zt, zs = zone_cfg[zr.zone]
        else:
            zc, zt, zs = "green", "‚ö™ –ù–ï –û–ü–†–ï–î–ï–õ–ï–ù–ê", "–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã"
        
        st.markdown(f'<div class="zone-card {zc}"><div class="zone-title">{zt}</div><div>{zs}</div><div style="font-size: 0.9rem; color: #555;">{zr.zone_reason}</div></div>', unsafe_allow_html=True)
        st.markdown(f"**–°—Ç–∞—Ç—É—Å –Æ–î:** {LEGAL_STATUS_LABELS[legal_status]}")
        
        cols = st.columns(4)
        cols[0].metric("üí∞ –°—É–º–º–∞", f"{amount:,.0f} ‚ÇΩ".replace(",", " "))
        cols[1].metric("‚è±Ô∏è –°—Ä–æ–∫", f"{zr.deadline_days} –¥–Ω." if zr.deadline_days else "‚Äî")
        cols[2].metric("üë§ –û—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω—ã–π", zr.responsible[:12] if zr.responsible else "‚Äî")
        cols[3].metric("‚öñÔ∏è –Æ–î", "–î–∞" if zr.requires_legal else "–ù–µ—Ç")
        
        if zr.approval_route:
            st.info("üìç " + " ‚Üí ".join(zr.approval_route))
        for w in zr.warnings:
            st.warning(w)
    
    st.markdown("---")
    st.markdown("### üìÑ –¢–µ–∫—Å—Ç –¥–æ–≥–æ–≤–æ—Ä–∞")
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–æ–≤
    uploaded = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª (TXT, DOCX, PDF)", type=["txt", "docx", "pdf"])
    if uploaded:
        success, result = DocumentLoader.load_file(uploaded)
        if success:
            st.session_state.contract_text = SecurityValidator.sanitize_text(result)
            st.success(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ: {len(st.session_state.contract_text):,} —Å–∏–º–≤–æ–ª–æ–≤")
        else:
            st.error(result)
    
    contract_text = st.text_area("–ò–ª–∏ –≤—Å—Ç–∞–≤—å—Ç–µ —Ç–µ–∫—Å—Ç:", value=st.session_state.contract_text, height=200)
    if contract_text != st.session_state.contract_text:
        st.session_state.contract_text = SecurityValidator.sanitize_text(contract_text)
    
    # –í—ã–±–æ—Ä —Ç–∏–ø–æ–≤–æ–π —Ñ–æ—Ä–º—ã
    all_tf = {**BUILTIN_TYPICAL_FORMS, **st.session_state.custom_typical_forms}
    tf_options = [("–ù–µ —Å—Ä–∞–≤–Ω–∏–≤–∞—Ç—å", None)] + [(f"{v['name']} ({v['code']})", k) for k, v in all_tf.items()]
    selected_tf_key = st.selectbox("–°—Ä–∞–≤–Ω–∏—Ç—å —Å —Ç–∏–ø–æ–≤–æ–π —Ñ–æ—Ä–º–æ–π:", tf_options, format_func=lambda x: x[0])[1]
    
    col_an1, col_an2 = st.columns(2)
    with col_an1:
        if st.button("üîç –°—Ä–∞–≤–Ω–∏—Ç—å —Å –¢–§ –∏ –Ω–∞–π—Ç–∏ —Ä–∏—Å–∫–∏", type="primary", use_container_width=True):
            if len(st.session_state.contract_text) < 100:
                st.error("–ú–∏–Ω–∏–º—É–º 100 —Å–∏–º–≤–æ–ª–æ–≤")
            elif not selected_tf_key:
                st.warning("–í—ã–±–µ—Ä–∏—Ç–µ —Ç–∏–ø–æ–≤—É—é —Ñ–æ—Ä–º—É")
            else:
                with st.spinner("–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º..."):
                    tf = all_tf.get(selected_tf_key)
                    st.session_state.comparison_result = AdvancedComparator.full_comparison(st.session_state.contract_text, tf)
                    st.session_state.selected_tf = tf
                st.rerun()
    
    with col_an2:
        api_key = st.session_state.get("_openai_key") or st.session_state.get("_anthropic_key")
        if st.button("ü§ñ AI-–∞–Ω–∞–ª–∏–∑ —Ä–∏—Å–∫–æ–≤", use_container_width=True, disabled=not api_key):
            if not api_key:
                st.warning("–í–≤–µ–¥–∏—Ç–µ API-–∫–ª—é—á –≤ –ù–∞—Å—Ç—Ä–æ–π–∫–∞—Ö")
            elif not st.session_state.comparison_result:
                st.warning("–°–Ω–∞—á–∞–ª–∞ –≤—ã–ø–æ–ª–Ω–∏—Ç–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –¢–§")
            else:
                with st.spinner("AI –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç..."):
                    prompt = AIAnalyzer.generate_risk_analysis_prompt(st.session_state.contract_text, st.session_state.comparison_result)
                    if st.session_state.get("_openai_key"):
                        st.session_state.ai_analysis = AIAnalyzer.call_openai(prompt, st.session_state._openai_key)
                    else:
                        st.session_state.ai_analysis = AIAnalyzer.call_anthropic(prompt, st.session_state._anthropic_key)
                st.rerun()
    
    # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
    if st.session_state.comparison_result:
        render_comparison_result(st.session_state.comparison_result)
    
    # AI –∞–Ω–∞–ª–∏–∑
    if st.session_state.ai_analysis:
        st.markdown("---")
        st.markdown("### ü§ñ –≠–∫—Å–ø–µ—Ä—Ç–Ω–æ–µ –∑–∞–∫–ª—é—á–µ–Ω–∏–µ (AI)")
        st.markdown(st.session_state.ai_analysis)

def render_comparison_result(result: Dict):
    st.markdown("---")
    st.markdown(f"### üìã –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å {result.get('form_name', '–¢–§')}")
    
    compliance = result.get('compliance_score', 0)
    
    cols = st.columns(4)
    cols[0].metric("üìä –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –¢–§", f"{compliance:.0f}%")
    cols[1].metric("‚úÖ –ù–∞–π–¥–µ–Ω–æ —Ä–∞–∑–¥–µ–ª–æ–≤", len(result.get("found_sections", [])))
    cols[2].metric("‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç", len(result.get("missing_sections", [])))
    cols[3].metric("‚ö†Ô∏è –û—Ç–∫–ª–æ–Ω–µ–Ω–∏–π", len(result.get("deviation_sections", [])))
    
    st.markdown(f"**–†–µ–∑—é–º–µ:** {result.get('summary', '')}")
    
    red_risks = [r for r in result.get('risks', []) if r.get('risk_level') == 'red']
    yellow_risks = [r for r in result.get('risks', []) if r.get('risk_level') == 'yellow']
    
    if red_risks:
        with st.expander(f"üî¥ –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ï –†–ò–°–ö–ò ({len(red_risks)})", expanded=True):
            for r in red_risks:
                st.markdown(f"""<div class="risk-item red"><strong>‚ö†Ô∏è {r.get('issue', '')}</strong><br><small>{r.get('context', '')[:300]}...</small></div>""", unsafe_allow_html=True)
    
    if yellow_risks:
        with st.expander(f"üü° –ü–†–ï–î–£–ü–†–ï–ñ–î–ï–ù–ò–Ø ({len(yellow_risks)})"):
            for r in yellow_risks:
                st.markdown(f"""<div class="risk-item yellow"><strong>‚ö° {r.get('issue', '')}</strong><br><small>{r.get('context', '')[:300]}...</small></div>""", unsafe_allow_html=True)
    
    with st.expander("üìë –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ø–æ —Ä–∞–∑–¥–µ–ª–∞–º"):
        for s in result.get('sections_analysis', []):
            comp = s.get('comparison', {})
            score = comp.get('combined_score', 0) * 100
            status = comp.get('status', 'missing')
            status_icon = {"match": "‚úÖ", "partial": "‚ö†Ô∏è", "deviation": "‚ùå", "missing": "‚ùå"}.get(status, "‚ùì")
            score_class = "score-high" if score >= 70 else "score-medium" if score >= 40 else "score-low"
            
            st.markdown(f"""**{status_icon} {s.get('section_name', '')}** {'(–æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–π)' if s.get('required') else ''} <span class="section-score {score_class}">{score:.0f}%</span>""", unsafe_allow_html=True)
            
            if comp.get('matched_section_name'):
                st.caption(f"–ù–∞–π–¥–µ–Ω –∫–∞–∫: {comp['matched_section_name']}")
            
            for r in s.get('risks', []):
                lvl = "üî¥" if r.get('risk_level') == 'red' else "üü°"
                st.markdown(f"  {lvl} {r.get('issue', '')}")
            
            st.markdown("---")

def render_reports_tab():
    st.markdown("### üìä –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á—ë—Ç–æ–≤")
    
    if not st.session_state.comparison_result and not st.session_state.zone_result:
        st.info("–°–Ω–∞—á–∞–ª–∞ –≤—ã–ø–æ–ª–Ω–∏—Ç–µ –∞–Ω–∞–ª–∏–∑ –¥–æ–≥–æ–≤–æ—Ä–∞ –Ω–∞ –≤–∫–ª–∞–¥–∫–µ ¬´–ê–Ω–∞–ª–∏–∑¬ª")
        return
    
    # –°–±–æ—Ä–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    inp = st.session_state.get('current_input') or AnalysisInput()
    
    data = {
        "analysis_id": hashlib.md5(datetime.now().isoformat().encode()).hexdigest()[:8],
        "counterparty": inp.counterparty or "–ù–µ —É–∫–∞–∑–∞–Ω",
        "contract_number": inp.contract_number or "",
        "contract_date": str(inp.contract_date) if inp.contract_date else "",
        "contract_type": inp.document_type or "",
        "document_form": inp.document_form.value if inp.document_form else "",
        "amount": inp.amount or 0,
        "legal_status": inp.legal_status.value if inp.legal_status else "",
        "legal_status_label": LEGAL_STATUS_LABELS.get(inp.legal_status, "") if inp.legal_status else "",
    }
    
    if st.session_state.zone_result:
        zr = st.session_state.zone_result
        data.update({
            "zone": zr.zone.value if zr.zone else "",
            "zone_reason": zr.zone_reason or "",
            "requires_legal": zr.requires_legal,
            "deadline_days": zr.deadline_days or 0,
            "approver": zr.responsible or "",
        })
    
    if st.session_state.comparison_result:
        cr = st.session_state.comparison_result
        data.update({
            "compliance_score": cr.get("compliance_score", 0),
            "tf_name": cr.get("form_name", ""),
            "tf_code": cr.get("form_code", ""),
            "risks": cr.get("risks", []),
            "sections_analysis": cr.get("sections_analysis", []),
            "missing_sections": cr.get("missing_sections", []),
            "deviation_sections": cr.get("deviation_sections", []),
            "recommendations": cr.get("recommendations", []),
            "summary": cr.get("summary", ""),
        })
    
    # –†–∏—Å–∫-—Å–∫–æ—Ä
    red_count = sum(1 for r in data.get('risks', []) if r.get('risk_level') == 'red')
    yellow_count = sum(1 for r in data.get('risks', []) if r.get('risk_level') == 'yellow')
    data["risk_score"] = min(10, red_count * 2 + yellow_count * 0.7)
    
    # –ó–∞–∫–ª—é—á–µ–Ω–∏–µ
    zone = data.get("zone", "")
    if zone == "red" or data["risk_score"] >= 6:
        data["conclusion"] = "–î–æ–≥–æ–≤–æ—Ä —Å–æ–¥–µ—Ä–∂–∏—Ç –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ï –†–ò–°–ö–ò. –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –Ω–∞–ø—Ä–∞–≤–∏—Ç—å –Ω–∞ –ø–æ–ª–Ω—É—é —é—Ä–∏–¥–∏—á–µ—Å–∫—É—é —ç–∫—Å–ø–µ—Ä—Ç–∏–∑—É –∏ —É—Å—Ç—Ä–∞–Ω–∏—Ç—å –≤—ã—è–≤–ª–µ–Ω–Ω—ã–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è –¥–æ –ø–æ–¥–ø–∏—Å–∞–Ω–∏—è."
    elif zone == "yellow" or data["risk_score"] >= 3:
        data["conclusion"] = "–î–æ–≥–æ–≤–æ—Ä —Ç—Ä–µ–±—É–µ—Ç –≤–Ω–∏–º–∞–Ω–∏—è. –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è —Å–æ–≥–ª–∞—Å–æ–≤–∞—Ç—å —Å –Æ–î –∏ —Ä–∞—Å—Å–º–æ—Ç—Ä–µ—Ç—å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∏ –æ—Ç–¥–µ–ª—å–Ω—ã—Ö —É—Å–ª–æ–≤–∏–π."
    else:
        data["conclusion"] = f"–°—É—â–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Ä–∏—Å–∫–æ–≤ –Ω–µ –≤—ã—è–≤–ª–µ–Ω–æ. –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Ç–∏–ø–æ–≤–æ–π —Ñ–æ—Ä–º–µ: {data.get('compliance_score', 0):.0f}%. –î–æ–ø—É—Å–∫–∞–µ—Ç—Å—è –ø–æ–¥–ø–∏—Å–∞–Ω–∏–µ –≤ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω–æ–º –ø–æ—Ä—è–¥–∫–µ."
    
    st.markdown("#### üìã –ü—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä")
    zone_emoji = {"green": "üü¢", "yellow": "üü°", "red": "üî¥"}.get(zone, "‚ö™")
    st.markdown(f"""
    **–ö–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç:** {data.get('counterparty')}  
    **–°—É–º–º–∞:** {data.get('amount', 0):,.0f} ‚ÇΩ  
    **–ó–æ–Ω–∞:** {zone_emoji} {zone.upper() if zone else '–ù–ï –û–ü–†–ï–î–ï–õ–ï–ù–ê'}  
    **–†–∏—Å–∫-—Å–∫–æ—Ä:** {data['risk_score']:.1f}/10  
    **–°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –¢–§:** {data.get('compliance_score', 0):.0f}%
    """)
    
    st.markdown("---")
    st.markdown("#### üì• –°–∫–∞—á–∞—Ç—å –æ—Ç—á—ë—Ç—ã")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        # PDF –æ—Ç—á–µ—Ç
        try:
            pdf_data = ReportGenerator.generate_pdf_report(data, st.session_state.user, st.session_state.ai_analysis)
            st.download_button(
                "üì• PDF –æ—Ç—á—ë—Ç",
                pdf_data,
                f"report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pdf",
                "application/pdf",
                use_container_width=True
            )
        except:
            st.warning("PDF –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ TXT")
    
    with col2:
        # DOCX –æ—Ç—á–µ—Ç
        try:
            docx_data = ReportGenerator.generate_docx_report(data, st.session_state.user, st.session_state.ai_analysis)
            st.download_button(
                "üì• DOCX –æ—Ç—á—ë—Ç",
                docx_data,
                f"report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.docx",
                "application/vnd.openxmlformats-officedocument.wordprocessingml.document",
                use_container_width=True
            )
        except:
            st.warning("DOCX –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
    
    with col3:
        # TXT –æ—Ç—á–µ—Ç
        txt_report = ReportGenerator.generate_text_report(data, st.session_state.user, st.session_state.ai_analysis)
        st.download_button(
            "üì• TXT –æ—Ç—á—ë—Ç",
            txt_report.encode('utf-8'),
            f"report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",
            "text/plain",
            use_container_width=True
        )
    
    st.markdown("---")
    st.markdown("#### üì• JSON –æ—Ç—á—ë—Ç—ã")
    
    col4, col5, col6 = st.columns(3)
    
    with col4:
        # JSON –¥–ª—è 1–°
        json_1c = ReportGenerator.generate_json_for_1c(data, st.session_state.user)
        st.download_button(
            "üì• JSON –¥–ª—è 1–°",
            json_1c,
            f"1c_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
            "application/json",
            use_container_width=True
        )
    
    with col5:
        # JSON –¥–ª—è –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π
        json_kb = ReportGenerator.generate_json_knowledge_base(data, st.session_state.user, st.session_state.contract_text)
        st.download_button(
            "üì• JSON –ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π",
            json_kb,
            f"kb_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
            "application/json",
            use_container_width=True
        )
    
    with col6:
        if st.button("üíæ –í –∏—Å—Ç–æ—Ä–∏—é", use_container_width=True):
            add_to_history(data)
            st.success("‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ!")
    
    # –ü—Ä–æ—Å–º–æ—Ç—Ä
    with st.expander("üëÅÔ∏è –ü—Ä–æ—Å–º–æ—Ç—Ä —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –æ—Ç—á—ë—Ç–∞"):
        st.text(txt_report)

def render_typical_forms_tab():
    st.markdown("### üìÇ –¢–∏–ø–æ–≤—ã–µ —Ñ–æ—Ä–º—ã")
    
    st.markdown("#### ‚¨ÜÔ∏è –ó–∞–≥—Ä—É–∑–∏—Ç—å —Å–≤–æ—é —Ç–∏–ø–æ–≤—É—é —Ñ–æ—Ä–º—É")
    
    uploaded_tf = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç—å –¢–§ (JSON)", type=["json"], key="tf_upload")
    if uploaded_tf:
        try:
            tf_data = json.loads(uploaded_tf.read().decode('utf-8'))
            if "name" in tf_data and "sections" in tf_data:
                code = tf_data.get("code", f"USER-{len(st.session_state.custom_typical_forms)+1}")
                st.session_state.custom_typical_forms[code] = tf_data
                st.success(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–∞: {tf_data['name']}")
            else:
                st.error("–ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç")
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞: {e}")
    
    st.markdown("##### –§–æ—Ä–º–∞—Ç JSON:")
    st.code("""{
  "name": "–ù–∞–∑–≤–∞–Ω–∏–µ",
  "code": "–¢–§-001",
  "version": "1.0",
  "sections": {
    "1. –†–ê–ó–î–ï–õ": {
      "required": true,
      "template": "–¢–µ–∫—Å—Ç...",
      "keywords": ["–∫–ª—é—á1", "–∫–ª—é—á2"],
      "risk_patterns": [{"pattern": "regex", "risk": "red", "issue": "–û–ø–∏—Å–∞–Ω–∏–µ"}]
    }
  },
  "global_risk_patterns": []
}""", language="json")
    
    st.markdown("---")
    st.markdown("#### üìã –î–æ—Å—Ç—É–ø–Ω—ã–µ —Ç–∏–ø–æ–≤—ã–µ —Ñ–æ—Ä–º—ã")
    
    all_tf = {**BUILTIN_TYPICAL_FORMS, **st.session_state.custom_typical_forms}
    
    for key, tf in all_tf.items():
        is_custom = key in st.session_state.custom_typical_forms
        badge = "üîµ –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∞—è" if is_custom else "‚ö™ –í—Å—Ç—Ä–æ–µ–Ω–Ω–∞—è"
        
        with st.expander(f"üìÑ {tf.get('name', key)} ({tf.get('code', key)}) {badge}"):
            st.markdown(f"**–í–µ—Ä—Å–∏—è:** {tf.get('version', '1.0')} | **–î–∞—Ç–∞:** {tf.get('date', '')}")
            
            st.markdown("**–†–∞–∑–¥–µ–ª—ã:**")
            for sname, sdata in tf.get("sections", {}).items():
                req = "‚úÖ" if sdata.get("required") else "‚ö™"
                st.markdown(f"{req} **{sname}**")
            
            st.download_button(
                "üì• –°–∫–∞—á–∞—Ç—å JSON",
                json.dumps(tf, ensure_ascii=False, indent=2),
                f"{key}.json",
                "application/json",
                key=f"dl_{key}"
            )
            
            if is_custom:
                if st.button(f"üóëÔ∏è –£–¥–∞–ª–∏—Ç—å", key=f"del_{key}"):
                    del st.session_state.custom_typical_forms[key]
                    st.rerun()

def render_regulation_tab():
    st.markdown("""
    <div style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); padding: 1.5rem; border-radius: 12px; color: white; margin-bottom: 1rem;">
        <h3 style="margin: 0;">üìã –†–µ–≥–ª–∞–º–µ–Ω—Ç –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è —Å –Æ–î</h3>
        <p style="margin: 0.5rem 0 0 0; opacity: 0.9;">–ê–û ¬´–ù–ü–ö¬ª | –í–µ—Ä—Å–∏—è 3.0</p>
    </div>
    """, unsafe_allow_html=True)
    
    st.markdown('<div class="zone-card green"><div class="zone-title">üü¢ –ó–ï–õ–ï–ù–ê–Ø ‚Äî –°–∞–º–æ—Å—Ç–æ—è—Ç–µ–ª—å–Ω–æ</div><p>–¢–§ ‚â§100–ö | –ù–µ—Ç–∏–ø–æ–≤—ã–µ ‚â§50–ö</p></div>', unsafe_allow_html=True)
    st.markdown('<div class="zone-card yellow"><div class="zone-title">üü° –ñ–ï–õ–¢–ê–Ø ‚Äî –Æ–î 5 –¥–Ω–µ–π</div><p>–¢–§ 100–ö-5–ú | –ù–µ—Ç–∏–ø. >50–ö | –ï–¥. –ø–æ—Å—Ç–∞–≤—â–∏–∫ >100–ö | –î–æ–≥–æ–≤–æ—Ä >3 –ª–µ—Ç</p></div>', unsafe_allow_html=True)
    st.markdown('<div class="zone-card red"><div class="zone-title">üî¥ –ö–†–ê–°–ù–ê–Ø ‚Äî –ü–æ–ª–Ω–æ–µ —Å–æ–ø—Ä–æ–≤–æ–∂–¥–µ–Ω–∏–µ</div><p>>5–ú | –¢–µ–Ω–¥–µ—Ä—ã >3–ú | –í–∞–≥–æ–Ω—ã/–ª–æ–∫–æ–º–æ—Ç–∏–≤—ã | –í–≠–î | –ü–û | –ù–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç—å | –ü—Ä–µ—Ç–µ–Ω–∑–∏–∏ | –ì–æ—Å–æ—Ä–≥–∞–Ω—ã</p></div>', unsafe_allow_html=True)
    st.warning("‚ö†Ô∏è –ó–ê–ü–†–ï–©–ï–ù–û –ø–æ–¥–ø–∏—Å–∞–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –ñ–µ–ª—Ç–æ–π/–ö—Ä–∞—Å–Ω–æ–π –∑–æ–Ω—ã –±–µ–∑ –≤–∏–∑—ã –Æ–î!")

def render_history_tab():
    st.markdown("### üìú –ò—Å—Ç–æ—Ä–∏—è –∞–Ω–∞–ª–∏–∑–æ–≤")
    if not st.session_state.history:
        st.info("–ò—Å—Ç–æ—Ä–∏—è –ø—É—Å—Ç–∞")
        return
    
    for h in st.session_state.history:
        z = {"green": "üü¢", "yellow": "üü°", "red": "üî¥"}.get(h.get("zone"), "‚ö™")
        with st.expander(f"{z} {h.get('counterparty', 'N/A')} | {h.get('timestamp', '')[:10]}"):
            col1, col2 = st.columns(2)
            with col1:
                st.markdown(f"**ID:** {h.get('id')}\n**–°—É–º–º–∞:** {h.get('amount', 0):,.0f} ‚ÇΩ\n**–†–∏—Å–∫-—Å–∫–æ—Ä:** {h.get('risk_score', 0):.1f}")
            with col2:
                st.markdown(f"**–°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –¢–§:** {h.get('compliance_score', 0):.0f}%")
            st.download_button("üì• JSON", json.dumps(h, ensure_ascii=False, indent=2), f"analysis_{h.get('id')}.json", key=f"hist_{h.get('id')}")

def render_settings_tab():
    st.markdown("### ‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏")
    st.warning("API-–∫–ª—é—á–∏ –ù–ï —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –º–µ–∂–¥—É —Å–µ—Å—Å–∏—è–º–∏")
    
    with st.expander("üîë API-–∫–ª—é—á–∏ –¥–ª—è AI-–∞–Ω–∞–ª–∏–∑–∞"):
        openai_key = st.text_input("OpenAI API Key", type="password", placeholder="sk-...", value=st.session_state.get("_openai_key", ""))
        anthropic_key = st.text_input("Anthropic API Key", type="password", placeholder="sk-ant-...", value=st.session_state.get("_anthropic_key", ""))
        if st.button("–ü—Ä–∏–º–µ–Ω–∏—Ç—å"):
            if openai_key:
                st.session_state._openai_key = openai_key
            if anthropic_key:
                st.session_state._anthropic_key = anthropic_key
            st.success("‚úÖ –ö–ª—é—á–∏ –ø—Ä–∏–º–µ–Ω–µ–Ω—ã")
    
    st.markdown("---")
    st.markdown("""
    **Legal Traffic Light v5.1 Enterprise**  
    ¬© –ê–û ¬´–ù–ü–ö¬ª 2025
    
    **–í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏:**
    - –ó–∞–≥—Ä—É–∑–∫–∞: TXT, DOCX, PDF
    - –û—Ç—á—ë—Ç—ã: PDF, DOCX, TXT, JSON
    - –ê–ª–≥–æ—Ä–∏—Ç–º: Jaccard + TF-IDF + N-grams + Levenshtein
    - AI-–∞–Ω–∞–ª–∏–∑: OpenAI / Anthropic
    - –ó–∞–≥—Ä—É–∑–∫–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏—Ö –¢–§
    
    **–ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏:**
    ```
    pip install streamlit python-docx fpdf2 PyPDF2 requests
    ```
    """)

def render_main():
    st.markdown("""
    <div class="main-header">
        <div class="traffic-light"><span class="tl-red"></span><span class="tl-yellow"></span><span class="tl-green"></span></div>
        <h2 style="margin: 0;">üö¶ Legal Traffic Light <span class="version-badge">v5.1 Enterprise</span></h2>
        <p style="margin: 0.5rem 0 0 0; opacity: 0.8;">–°–∏—Å—Ç–µ–º–∞ –∞–Ω–∞–ª–∏–∑–∞ –¥–æ–≥–æ–≤–æ—Ä–æ–≤ –ê–û ¬´–ù–ü–ö¬ª</p>
    </div>
    """, unsafe_allow_html=True)
    
    render_sidebar()
    
    tabs = st.tabs(["üìù –ê–Ω–∞–ª–∏–∑", "üìä –û—Ç—á—ë—Ç—ã", "üìÇ –¢–∏–ø–æ–≤—ã–µ —Ñ–æ—Ä–º—ã", "üìã –†–µ–≥–ª–∞–º–µ–Ω—Ç", "üìú –ò—Å—Ç–æ—Ä–∏—è", "‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏"])
    with tabs[0]:
        render_analysis_tab()
    with tabs[1]:
        render_reports_tab()
    with tabs[2]:
        render_typical_forms_tab()
    with tabs[3]:
        render_regulation_tab()
    with tabs[4]:
        render_history_tab()
    with tabs[5]:
        render_settings_tab()

def main():
    apply_styles()
    init_session()
    if not st.session_state.authenticated:
        render_auth()
    else:
        render_main()

if __name__ == "__main__":
    main()
